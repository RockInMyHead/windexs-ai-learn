import Navigation from "@/components/Navigation";
import { useParams } from "react-router-dom";
import { getCourseDisplayName } from "@/lib/utils";
import { Mic, MicOff, Volume2, VolumeX, Phone, PhoneOff, Loader2 } from "lucide-react";
import { Button } from "@/components/ui/button";
import { Card, CardContent } from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import { useState, useRef, useCallback, useEffect } from "react";
import { useAuth } from "@/contexts/AuthContext";
import { useToast } from "@/hooks/use-toast";

// Web Speech API types
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message?: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((event: Event) => void) | null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;
  onend: ((event: Event) => void) | null;
}

declare global {
  interface Window {
    SpeechRecognition?: new () => SpeechRecognition;
    webkitSpeechRecognition?: new () => SpeechRecognition;
  }
}

const VoiceChat = () => {
  const { courseId } = useParams();
  const { token } = useAuth();
  const { toast } = useToast();

  const [isRecording, setIsRecording] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [isGeneratingResponse, setIsGeneratingResponse] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isMicEnabled, setIsMicEnabled] = useState(true);
  const [ttsInterrupted, setTtsInterrupted] = useState(false);
  const [isSoundEnabled, setIsSoundEnabled] = useState(true);
  const [userProfile, setUserProfile] = useState<any>(null);

  const speechRecognitionRef = useRef<SpeechRecognition | null>(null);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);
  const lastTranscriptRef = useRef<string>('');

  // Function to stop current TTS playback
  const stopCurrentTTS = useCallback(() => {
    if (currentAudioRef.current) {
      console.log('üõë –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ –ø—Ä–µ—Ä—ã–≤–∞—é —Ç–µ–∫—É—â—É—é –æ–∑–≤—É—á–∫—É...');

      // Multiple ways to ensure audio stops
      try {
        currentAudioRef.current.pause();
        currentAudioRef.current.currentTime = 0;
        currentAudioRef.current.volume = 0;
        currentAudioRef.current.muted = true;

        // Remove all event listeners
        currentAudioRef.current.onplay = null;
        currentAudioRef.current.onended = null;
        currentAudioRef.current.onerror = null;

        // Force garbage collection hint
        currentAudioRef.current.src = '';
        currentAudioRef.current.load();
      } catch (error) {
        console.log('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏ audio:', error);
      }

    currentAudioRef.current = null;
  }

  setIsSpeaking(false);
  setTtsInterrupted(true);

  // –°–±—Ä–æ—Å–∏—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —á–µ—Ä–µ–∑ 2 —Å–µ–∫—É–Ω–¥—ã
  setTimeout(() => setTtsInterrupted(false), 2000);
}, []);

  // Initialize Web Speech API
  const initializeSpeechRecognition = useCallback(() => {
    // Check if Web Speech API is supported
    const SpeechRecognition = window.SpeechRecognition || (window as any).webkitSpeechRecognition;

    if (!SpeechRecognition) {
      console.error('‚ùå Web Speech API –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ —ç—Ç–æ–º –±—Ä–∞—É–∑–µ—Ä–µ');
      return null;
    }

    console.log('üé§ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Web Speech API...');
    const recognition = new SpeechRecognition();

    // Configure recognition
    recognition.continuous = true; // Keep listening continuously
    recognition.interimResults = true; // Enable interim results to detect speech early
    recognition.lang = 'ru-RU'; // Russian language
    recognition.maxAlternatives = 1;

    // Event handlers
    recognition.onstart = () => {
      console.log('üéôÔ∏è Speech recognition started');
      console.log('üéôÔ∏è Recognition —Å–æ—Å—Ç–æ—è–Ω–∏–µ: started');
      setIsTranscribing(true);
    };

    recognition.onresult = async (event) => {
      // Don't process if mic is disabled
      if (!isMicEnabled) {
        console.log('üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç');
        return;
      }

      const result = event.results[event.results.length - 1]; // Get the last result

      // –ü—Ä–æ–≤–µ—Ä—è—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ isSpeaking, –Ω–æ –∏ –Ω–∞–ª–∏—á–∏–µ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞—É–¥–∏–æ
      if (!result.isFinal && (isSpeaking || currentAudioRef.current)) {
        const interimTranscript = result[0].transcript.trim();

        // –ü—Ä–µ—Ä—ã–≤–∞—Ç—å –¥–∞–∂–µ –ø—Ä–∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–≤—É–∫–∞—Ö (—á—Ç–æ–±—ã —Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å –±—ã—Å—Ç—Ä–µ–µ)
        if (interimTranscript.length > 0 || result[0].confidence > 0.3) {
          console.log('üõë –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Ä–µ—á—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é TTS...');
          console.log('üìù Interim transcript:', interimTranscript);
          stopCurrentTTS();
        }
      }

      if (result.isFinal) {
        const transcript = result[0].transcript.trim();
        console.log('üë§ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:', transcript);
        console.log('üéØ –¢–µ–∫—Å—Ç –¥–ª—è –≤—ã–≤–æ–¥–∞:', transcript);

        if (transcript) {
          // Double-check TTS is stopped
          if (isSpeaking) {
            console.log('üé§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ—Ä–≤–∞–ª –æ–∑–≤—É—á–∫—É, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é TTS...');
            stopCurrentTTS();
          }

          // Save current transcript for context
          lastTranscriptRef.current = transcript;

          // Send to LLM and get response (include previous context if interrupted)
          const llmResponse = await sendToLLM(transcript);

          // Small delay to ensure previous TTS is fully stopped
          await new Promise(resolve => setTimeout(resolve, 100));

          // Speak the response (recognition continues automatically in continuous mode)
          await speakText(llmResponse);

          console.log('‚úÖ –û—Ç–≤–µ—Ç –æ–∑–≤—É—á–µ–Ω, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ...');
        }
      }
    };

    recognition.onerror = (event) => {
      console.error('‚ùå Speech recognition error:', event.error);
      setIsTranscribing(false);
    };

    recognition.onend = () => {
      console.log('üéôÔ∏è Speech recognition ended');
      setIsTranscribing(false);

      // In continuous mode, onend usually means an error occurred
      // Try to restart if we're still recording
      if (isRecording) {
        console.log('üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø–æ—Å–ª–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏...');
        setTimeout(() => {
          startSpeechRecognition();
        }, 1000); // Longer delay for error recovery
      }
    };

    speechRecognitionRef.current = recognition;
    console.log('‚úÖ Web Speech API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
    return recognition;
  }, [isRecording, isMicEnabled, isSoundEnabled]);

  // Start speech recognition
  const startSpeechRecognition = useCallback(() => {
    if (!speechRecognitionRef.current) {
      console.log('‚ùå Speech recognition –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
      return;
    }

    console.log('üéôÔ∏è –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏...', {
      isRecording,
      isTranscribing,
      recognitionState: speechRecognitionRef.current ? 'exists' : 'null'
    });

    try {
      // Ensure recognition is stopped before starting
      try {
        speechRecognitionRef.current.stop();
        console.log('üõë Recognition –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º');
      } catch (e) {
        // Ignore if already stopped
        console.log('üõë Recognition —É–∂–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω');
      }

      console.log('üéôÔ∏è –ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏...');
      speechRecognitionRef.current.start();
      console.log('‚úÖ start() –≤—ã–∑–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ');
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ speech recognition:', error);
      console.error('‚ùå –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:', {
        message: error.message,
        name: error.name,
        stack: error.stack
      });
      setIsTranscribing(false);
    }
  }, [isRecording, isTranscribing]);

  // Start/stop recording
  const handleStartStopRecording = useCallback(async () => {
    if (isRecording) {
      // Stop recording
      console.log('üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...');
      setIsRecording(false);
      setIsTranscribing(false);

      if (speechRecognitionRef.current) {
        try {
          speechRecognitionRef.current.stop();
        } catch (error) {
          console.log('Speech recognition already stopped');
        }
      }
    } else {
      // Start recording (only if mic is enabled)
      if (!isMicEnabled) {
        toast({
          title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω",
          description: "–í–∫–ª—é—á–∏—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω –¥–ª—è –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏",
          variant: "destructive"
        });
        return;
      }

      console.log('üé§ –ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏...');

      try {
        // Initialize Web Speech API if not already done
        if (!speechRecognitionRef.current) {
          const recognition = initializeSpeechRecognition();
          if (!recognition) {
            console.error('‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å Web Speech API');
            return;
          }
        }

        setIsRecording(true);

        // Start speech recognition
        startSpeechRecognition();

        console.log('üé§ –ó–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
      } catch (error) {
        console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–ø–∏—Å–∏:', error);
      }
    }
  }, [isRecording, initializeSpeechRecognition, startSpeechRecognition, isMicEnabled, toast]);

  // Toggle microphone
  const handleToggleMic = useCallback(() => {
    if (isMicEnabled) {
      // Disable mic
      console.log('üé§ –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...');
      setIsMicEnabled(false);
      if (isRecording) {
        // Stop recording if it's active
        setIsRecording(false);
        setIsTranscribing(false);
        if (speechRecognitionRef.current) {
          try {
            speechRecognitionRef.current.stop();
          } catch (error) {
            console.log('Speech recognition already stopped');
          }
        }
      }
      toast({
        title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω",
        description: "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"
      });
    } else {
      // Enable mic
      console.log('üé§ –í–∫–ª—é—á–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...');
      setIsMicEnabled(true);
      toast({
        title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –≤–∫–ª—é—á–µ–Ω",
        description: "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∞–∫—Ç–∏–≤–Ω–æ"
      });
    }
  }, [isMicEnabled, isRecording, toast]);

  // Toggle sound
  const handleToggleSound = useCallback(() => {
    if (isSoundEnabled) {
      // Disable sound
      console.log('üîä –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∑–≤—É–∫–∞...');
      setIsSoundEnabled(false);
      toast({
        title: "–ó–≤—É–∫ –æ—Ç–∫–ª—é—á–µ–Ω",
        description: "–û—Ç–≤–µ—Ç—ã –Ω–µ –±—É–¥—É—Ç –æ–∑–≤—É—á–∏–≤–∞—Ç—å—Å—è"
      });
    } else {
      // Enable sound
      console.log('üîä –í–∫–ª—é—á–µ–Ω–∏–µ –∑–≤—É–∫–∞...');
      setIsSoundEnabled(true);
      toast({
        title: "–ó–≤—É–∫ –≤–∫–ª—é—á–µ–Ω",
        description: "–û—Ç–≤–µ—Ç—ã –±—É–¥—É—Ç –æ–∑–≤—É—á–∏–≤–∞—Ç—å—Å—è"
      });
    }
  }, [isSoundEnabled, toast]);

  // Get user profile from API
  const getUserProfile = useCallback(async () => {
    try {
      const response = await fetch('https://teacher.windexs.ru/api/profile', {
        headers: {
          'Authorization': `Bearer ${token}`
        }
      });

      if (response.ok) {
        const profile = await response.json();
        setUserProfile(profile);
        console.log('üìã –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω:', profile);
        return profile;
      }
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ—Ñ–∏–ª—è:', error);
    }
    return null;
  }, [token]);

  // Get course name from courseId
  const getCourseName = useCallback(() => {
    return getCourseDisplayName(courseId || "");
  }, [courseId]);

  // Send transcribed text to LLM with Julia's system prompt
  const sendToLLM = useCallback(async (userMessage: string): Promise<string> => {
    setIsGeneratingResponse(true);

    try {
      console.log('ü§ñ –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ LLM...');

      // Get user profile if not loaded
      let profile = userProfile;
      if (!profile) {
        profile = await getUserProfile();
      }

      // Get course information
      const courseName = getCourseDisplayName(courseId || "");

      // Build context information
      const contextInfo = [];
      if (courseName) {
        contextInfo.push(`–ö—É—Ä—Å: ${courseName}`);
      }
      if (profile) {
        console.log('üìä –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è LLM:', profile);
        if (profile.learning_style) {
          contextInfo.push(`–°—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è: ${profile.learning_style}`);
        }
        if (profile.difficulty_level) {
          contextInfo.push(`–£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: ${profile.difficulty_level}`);
        }
        if (profile.interests) {
          // Safely handle interests - could be string, array, or object
          let interestsStr = '';
          if (typeof profile.interests === 'string') {
            interestsStr = profile.interests;
          } else if (Array.isArray(profile.interests)) {
            interestsStr = profile.interests.join(', ');
          } else if (profile.interests) {
            interestsStr = JSON.stringify(profile.interests);
          }
          if (interestsStr) {
            contextInfo.push(`–ò–Ω—Ç–µ—Ä–µ—Å—ã: ${interestsStr}`);
          }
        }
      }

      const contextString = contextInfo.length > 0 ? `\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:\n${contextInfo.join('\n')}` : '';

      // NOTE:
      // –†–∞–Ω—å—à–µ –º—ã —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª–∏ –∑–¥–µ—Å—å –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º—Ç —É—á–∏—Ç–µ–ª—è –Æ–ª–∏–∏ (teacherJuliaPrompt)
      // –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –µ–≥–æ –∫–∞–∫ content. –¢–µ–ø–µ—Ä—å –≠–¢–û –î–ï–õ–ê–ï–¢ –°–ï–†–í–ï–†:
      //  - —Å–µ—Ä–≤–µ—Ä –∑–Ω–∞–µ—Ç –∫—É—Ä—Å, –ø—Ä–æ—Ñ–∏–ª—å, –¥–æ–º–∞—à–∫–∏
      //  - —Å–∞–º –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç (generateVoiceChatPrompt)
      // –ü–æ—ç—Ç–æ–º—É —Å —Ñ—Ä–æ–Ω—Ç–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û —á–∏—Å—Ç—É—é —Ä–µ–ø–ª–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

      // Prepare message with context if TTS was interrupted
      let messageContent = userMessage;
      if (isSpeaking && lastTranscriptRef.current && lastTranscriptRef.current !== userMessage) {
        // Include previous context when TTS was interrupted
        messageContent = `–ü—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: "${lastTranscriptRef.current}". –ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å: "${userMessage}"`;
        console.log('üìù –ü–µ—Ä–µ–¥–∞—é –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ—Ä–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:', messageContent);
      }

      // Send raw user message to server API
      console.log('üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ VoiceChat:', {
        url: `https://teacher.windexs.ru/api/chat/${courseId}/message`,
        content: messageContent,
        messageType: 'voice',
        token: token ? 'present' : 'missing'
      });

      const response = await fetch(`https://teacher.windexs.ru/api/chat/${courseId}/message`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${token}`
        },
        body: JSON.stringify({
          // –í content –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ.
          // –°–µ—Ä–≤–µ—Ä –ø–æ—Å—Ç—Ä–æ–∏—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç —É—á–∏—Ç–µ–ª—è –Æ–ª–∏–∏ —Å–∞–º.
          content: messageContent,
          messageType: 'voice',
          interrupted: isSpeaking // Flag to indicate if this was an interruption
        })
      });

      if (!response.ok) {
        let errorData = { error: 'Unknown error' };
        try {
          const text = await response.text();
          if (text) {
            errorData = JSON.parse(text);
          }
        } catch (parseError) {
          console.error('‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞:', parseError);
        }
        console.error('‚ùå –û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞ —Å –æ—à–∏–±–∫–æ–π:', response.status, errorData);
        throw new Error(errorData.error || errorData.details || 'Failed to get LLM response');
      }

      // Parse response safely
      let data;
      try {
        const text = await response.text();
        console.log('üì• –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞:', text.substring(0, 200));
        data = JSON.parse(text);
      } catch (parseError) {
        console.error('‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON:', parseError);
        throw new Error('Invalid JSON response from server');
      }

      console.log('‚úÖ LLM –æ—Ç–≤–µ—Ç–∏–ª:', data.message);

      return data.message || '–ò–∑–≤–∏–Ω–∏, —è –Ω–µ —Å–º–æ–≥–ª–∞ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.';

    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ LLM:', error);
      console.error('‚ùå –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:', {
        message: error.message,
        stack: error.stack,
        name: error.name
      });
      return '–ò–∑–≤–∏–Ω–∏, —É –º–µ–Ω—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–µ–ø–æ–ª–∞–¥–∫–∏. –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É.';
    } finally {
      setIsGeneratingResponse(false);
    }
  }, [token, userProfile, courseId, getUserProfile, isSpeaking]);

  // Convert text to speech using OpenAI TTS
  const speakText = useCallback(async (text: string) => {
    // Don't speak if sound is disabled
    if (!isSoundEnabled) {
      console.log('üîá –ó–≤—É–∫ –æ—Ç–∫–ª—é—á–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–∑–≤—É—á–∫—É');
      return;
    }

    setIsSpeaking(true);

    // –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –¥–ª—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è TTS (–µ—Å–ª–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –≤–∫–ª—é—á–µ–Ω)
    if (isMicEnabled && !isRecording) {
      console.log('üé§ –í–∫–ª—é—á–∞—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –¥–ª—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è TTS');
      try {
        if (!speechRecognitionRef.current) {
          const recognition = initializeSpeechRecognition();
          if (recognition) {
            speechRecognitionRef.current = recognition;
          }
        }
        if (speechRecognitionRef.current) {
          speechRecognitionRef.current.start();
          setIsRecording(true);
          console.log('‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∑–∞–ø—É—â–µ–Ω–æ –¥–ª—è TTS –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è');
        }
      } catch (error) {
        console.error('‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏:', error);
      }
    }

    try {
      console.log('üîä –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤ OpenAI TTS...');

      const response = await fetch('https://teacher.windexs.ru/api/tts', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${token}`
        },
        body: JSON.stringify({
          text: text,
          voice: 'shimmer' // Bright and energetic female voice
        })
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
        throw new Error(errorData.error || errorData.details || 'Failed to generate speech');
      }

      // Get audio blob
      const audioBlob = await response.blob();
      console.log('‚úÖ –ü–æ–ª—É—á–µ–Ω –∞—É–¥–∏–æ —Ñ–∞–π–ª, —Ä–∞–∑–º–µ—Ä:', audioBlob.size);

      // –£–ë–†–ê–¢–¨: stopCurrentTTS(); - –Ω–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å TTS –ø–µ—Ä–µ–¥ –Ω–æ–≤—ã–º!

      // Double-check that audio is stopped (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å)
      if (currentAudioRef.current) {
        console.log('‚ö†Ô∏è Audio –≤—Å–µ –µ—â–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ø–æ—Å–ª–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–∞–µ–º...');
        currentAudioRef.current = null;
      }

      // Create audio element and play
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      currentAudioRef.current = audio;

      // Event handlers
      audio.onplay = () => {
        console.log('üîä –û–∑–≤—É—á–∫–∞ –Ω–∞—á–∞—Ç–∞');
      };

      audio.onended = () => {
        console.log('‚úÖ –û–∑–≤—É—á–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞');
        URL.revokeObjectURL(audioUrl);
        currentAudioRef.current = null;
        setIsSpeaking(false);

        // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è TTS
        if (speechRecognitionRef.current && isRecording) {
          console.log('üé§ –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –ø–æ—Å–ª–µ TTS');
          try {
            speechRecognitionRef.current.stop();
            setIsRecording(false);
          } catch (error) {
            console.log('‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:', error);
          }
        }
      };

      audio.onerror = (event) => {
        console.error('‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ:', event);
        URL.revokeObjectURL(audioUrl);
        currentAudioRef.current = null;
        setIsSpeaking(false);

        // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        if (speechRecognitionRef.current && isRecording) {
          try {
            speechRecognitionRef.current.stop();
            setIsRecording(false);
          } catch (e) {
            console.log('‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ TTS:', e);
          }
        }
        toast({
          title: "–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏",
          description: "–ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –∞—É–¥–∏–æ",
          variant: "destructive"
        });
      };

      // Small delay to ensure clean start
      await new Promise(resolve => setTimeout(resolve, 50));

      // Start playing
      await audio.play();

    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ TTS:', error);
      setIsSpeaking(false);

      // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
      if (speechRecognitionRef.current && isRecording) {
        try {
          speechRecognitionRef.current.stop();
          setIsRecording(false);
        } catch (e) {
          console.log('‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ TTS:', e);
        }
      }

      toast({
        title: "–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏",
        description: `–ù–µ —É–¥–∞–ª–æ—Å—å –æ–∑–≤—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç: ${error.message}`,
        variant: "destructive"
      });
    }
  }, [token, toast, isSoundEnabled]);

  // Load user profile on component mount
  useEffect(() => {
    if (token) {
      getUserProfile();
    }
  }, [token, getUserProfile]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      console.log('üßπ –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏');
      if (speechRecognitionRef.current) {
        try {
          speechRecognitionRef.current.stop();
        } catch (error) {
          // Already stopped
        }
      }
      // Stop current TTS
      stopCurrentTTS();
      // Stop speech synthesis (fallback)
      if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel();
      }
    };
  }, [stopCurrentTTS]);

  return (
    <div className="min-h-screen bg-background">
      <Navigation />

      {/* TTS interruption indicator */}
      {ttsInterrupted && (
        <div className="fixed top-20 left-1/2 transform -translate-x-1/2 z-50">
          <div className="bg-red-500 text-white px-4 py-2 rounded-lg shadow-lg animate-bounce flex items-center gap-2">
            <div className="w-3 h-3 bg-white rounded-full animate-pulse"></div>
            <span className="text-sm font-medium">üé§ –†–µ—á—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ - TTS –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω</span>
          </div>
        </div>
      )}

      <main className="container mx-auto px-4 pt-24 pb-16">
        <div className="max-w-2xl mx-auto">
          <div className="text-center mb-8 animate-fade-in">
            <h1 className="text-3xl md:text-4xl font-bold mb-4 bg-gradient-to-r from-primary to-emerald-600 bg-clip-text text-transparent">
              –ì–æ–ª–æ—Å–æ–≤–æ–µ –æ–±—â–µ–Ω–∏–µ
            </h1>
            <p className="text-muted-foreground">
              {getCourseDisplayName(courseId || "")}
            </p>
          </div>

          <Card className="shadow-2xl animate-fade-in">
            <CardContent className="p-8 md:p-12">
              <div className="text-center space-y-6">
                {/* Status Indicator */}
                <div className="relative inline-block">
                  <div className={`w-32 h-32 md:w-40 md:h-40 rounded-full ${
                    isRecording ? 'bg-green-500/20' : 'bg-muted'
                  } flex items-center justify-center transition-all duration-300`}>
                    <Mic className={`w-16 h-16 md:w-20 md:h-20 ${
                      isRecording ? 'text-green-500' : 'text-muted-foreground'
                    }`} />
                  </div>
                  {isRecording && (
                    <div className="absolute inset-0 rounded-full animate-ping bg-green-500/20"></div>
                  )}
                </div>

                {/* Status Text */}
                <div>
                  <h2 className="text-2xl font-bold mb-2">
                    {isRecording ? "–ò–¥–µ—Ç –∑–∞–ø–∏—Å—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ" : "–ì–æ—Ç–æ–≤ –∫ –∑–∞–ø–∏—Å–∏"}
                  </h2>
                  <p className="text-muted-foreground mb-3">
                    {isRecording
                      ? "–ì–æ–≤–æ—Ä–∏—Ç–µ —Å–≤–æ–±–æ–¥–Ω–æ - —Ç–µ–∫—Å—Ç –≤—ã–≤–æ–¥–∏—Ç—Å—è –≤ –∫–æ–Ω—Å–æ–ª—å"
                      : "–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –¥–ª—è –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏"
                    }
                  </p>

                  {/* Recording Status */}
                  <div className="flex flex-wrap justify-center gap-2">
                    {isRecording && (
                      <Badge variant="secondary" className="bg-green-100 text-green-700 border-green-200 animate-pulse">
                        üé§ –ó–∞–ø–∏—Å—å –∞–∫—Ç–∏–≤–Ω–∞...
                      </Badge>
                    )}
                    {isTranscribing && (
                      <Badge variant="outline" className="bg-blue-50 text-blue-700 border-blue-200">
                        <Loader2 className="w-3 h-3 mr-1 animate-spin" />
                        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...
                      </Badge>
                    )}
                    {isGeneratingResponse && (
                      <Badge variant="outline" className="bg-purple-50 text-purple-700 border-purple-200">
                        <Loader2 className="w-3 h-3 mr-1 animate-spin" />
                        ü§ñ –î—É–º–∞—é...
                      </Badge>
                    )}
                    {isSpeaking && (
                      <Badge variant="outline" className="bg-orange-50 text-orange-700 border-orange-200 animate-pulse">
                        üîä –ì–æ–≤–æ—Ä—é...
                      </Badge>
                    )}
                    {!isRecording && (
                      <Badge variant="outline" className="bg-gray-50 text-gray-700 border-gray-200">
                        üîá –û–∂–∏–¥–∞–Ω–∏–µ –Ω–∞—á–∞–ª–∞
                      </Badge>
                    )}
                  </div>
                </div>

                {/* Control Buttons */}
                <div className="flex flex-wrap justify-center gap-4">
                  <Button
                    variant="outline"
                    size="lg"
                    className={`w-16 h-16 rounded-full ${isMicEnabled ? 'bg-green-50 border-green-200 hover:bg-green-100' : 'bg-red-50 border-red-200 hover:bg-red-100'}`}
                    onClick={handleToggleMic}
                    title={isMicEnabled ? "–û—Ç–∫–ª—é—á–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω" : "–í–∫–ª—é—á–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω"}
                  >
                    {isMicEnabled ? (
                      <Mic className="w-6 h-6 text-green-600" />
                    ) : (
                      <MicOff className="w-6 h-6 text-red-600" />
                    )}
                  </Button>
                  <Button
                    variant="outline"
                    size="lg"
                    className={`w-16 h-16 rounded-full ${isSoundEnabled ? 'bg-blue-50 border-blue-200 hover:bg-blue-100' : 'bg-gray-50 border-gray-200 hover:bg-gray-100'}`}
                    onClick={handleToggleSound}
                    title={isSoundEnabled ? "–û—Ç–∫–ª—é—á–∏—Ç—å –∑–≤—É–∫" : "–í–∫–ª—é—á–∏—Ç—å –∑–≤—É–∫"}
                  >
                    {isSoundEnabled ? (
                      <Volume2 className="w-6 h-6 text-blue-600" />
                    ) : (
                      <VolumeX className="w-6 h-6 text-gray-600" />
                    )}
                  </Button>
                </div>

                {/* Main Action Button */}
                <Button
                  size="lg"
                  className={`w-full max-w-xs h-14 text-lg ${isRecording ? 'bg-red-500 hover:bg-red-600' : ''}`}
                  onClick={handleStartStopRecording}
                >
                  {isRecording ? (
                    <>
                      <PhoneOff className="w-5 h-5 mr-2" />
                      –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å
                    </>
                  ) : (
                    <>
                      <Phone className="w-5 h-5 mr-2" />
                      –ù–∞—á–∞—Ç—å —É—Ä–æ–∫
                    </>
                  )}
                </Button>
              </div>
            </CardContent>
          </Card>

        </div>
      </main>
    </div>
  );
};

export default VoiceChat;
