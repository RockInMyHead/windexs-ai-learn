import Navigation from "@/components/Navigation";
import { useParams } from "react-router-dom";
import { getCourseDisplayName } from "@/lib/utils";
import { Mic, MicOff, Volume2, VolumeX, Phone, PhoneOff, Loader2 } from "lucide-react";
import { Button } from "@/components/ui/button";
import { Card, CardContent } from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import { useState, useRef, useCallback, useEffect } from "react";
import { useAuth } from "@/contexts/AuthContext";
import { useToast } from "@/hooks/use-toast";

// Web Speech API types

// –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≥–æ–ª–æ—Å–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —ç—Ö–∞
const VOICE_DETECTION_THRESHOLD = 15; // –ë–∞–∑–æ–≤—ã–π –ø–æ—Ä–æ–≥ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≥–æ–ª–æ—Å–∞
const ECHO_SIMILARITY_THRESHOLD = 0.7; // –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç—Ö–∞
const ECHO_BUFFER_TIME = 500; // –í—Ä–µ–º—è –≤ –º—Å –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª–∞ TTS, –∫–æ–≥–¥–∞ —ç—Ö–æ –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message?: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((event: Event) => void) | null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;
  onend: ((event: Event) => void) | null;
}

declare global {
  interface Window {
    SpeechRecognition?: new () => SpeechRecognition;
    webkitSpeechRecognition?: new () => SpeechRecognition;
    mozSpeechRecognition?: new () => SpeechRecognition; // Firefox support
  }
}

const VoiceChat = () => {
  const { courseId } = useParams();
  const { token } = useAuth();
  const { toast } = useToast();

  const [isRecording, setIsRecording] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [isGeneratingResponse, setIsGeneratingResponse] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isMicEnabled, setIsMicEnabled] = useState(true);
  const [isSoundEnabled, setIsSoundEnabled] = useState(true);
  const [userProfile, setUserProfile] = useState<any>(null);
  const [useFallbackTranscription, setUseFallbackTranscription] = useState(false);

  const speechRecognitionRef = useRef<SpeechRecognition | null>(null);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);
  const lastTranscriptRef = useRef<string>('');
  const cleanTranscriptRef = useRef<string>(''); // Track clean transcript without TTS echo
  const currentTTSTextRef = useRef<string>(''); // Store current TTS text to detect echo

  // –ú–µ—Ö–∞–Ω–∏–∑–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–º–µ–Ω—ã –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏
  const generationIdRef = useRef<number>(0);

  // –ê—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
  const audioContextRef = useRef<AudioContext | null>(null);
  const audioAnalyserRef = useRef<AnalyserNode | null>(null);
  const microphoneSourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const volumeMonitorRef = useRef<number | null>(null);

  // –°–æ—Å—Ç–æ—è–Ω–∏–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ
  const isPlayingAudioRef = useRef<boolean>(false);

  // –û—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
  const audioQueueRef = useRef<ArrayBuffer[]>([]);

  // –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–∑–≤—É—á–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —ç—Ö–∞
  const ttsProgressRef = useRef<{
    startTime: number;
    text: string;
    duration: number; // –ø—Ä–∏–º–µ—Ä–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –º—Å
    words: string[]; // —Å–ª–æ–≤–∞ –ø–æ –ø–æ—Ä—è–¥–∫—É
    currentWordIndex: number;
  } | null>(null);
  
  // Fallback recording refs (for browsers without Web Speech API)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const mediaStreamRef = useRef<MediaStream | null>(null);


  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
  const initializeAudioContext = useCallback(async (): Promise<AudioContext> => {
    if (audioContextRef.current) {
      return audioContextRef.current;
    }

    const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
    audioContextRef.current = new AudioContextClass();

    // Resume context if suspended (required by some browsers)
    if (audioContextRef.current.state === 'suspended') {
      await audioContextRef.current.resume();
    }

    return audioContextRef.current;
  }, []);

  // –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
  const stopAssistantSpeech = useCallback(() => {
    console.log('üõë –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Ä–µ—á—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞');

    // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º generationId –¥–ª—è –æ—Ç–º–µ–Ω—ã —Ç–µ–∫—É—â–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    generationIdRef.current += 1;

    // –û—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ
    audioQueueRef.current = [];

    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
    if (currentAudioRef.current) {
      try {
        currentAudioRef.current.pause();
        currentAudioRef.current.currentTime = 0;
        currentAudioRef.current.volume = 0;
        currentAudioRef.current.muted = true;
        currentAudioRef.current.src = '';
        currentAudioRef.current.load();
      } catch (error) {
        console.warn('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∞—É–¥–∏–æ:', error);
      }
      currentAudioRef.current = null;
    }


    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    isPlayingAudioRef.current = false;
    setIsSpeaking(false);

    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
    ttsProgressRef.current = null;
  }, []);

  // Function to stop current TTS playback
  const stopCurrentTTS = useCallback(() => {
    stopAssistantSpeech();
  }, []);

  // Check if Web Speech API is available
  const isWebSpeechAvailable = useCallback(() => {
    const SpeechRecognition = window.SpeechRecognition ||
      (window as any).webkitSpeechRecognition ||
      (window as any).mozSpeechRecognition;
    return !!SpeechRecognition;
  }, []);

  // Transcribe audio using OpenAI Whisper API (fallback for browsers without Web Speech API)
  const transcribeWithOpenAI = useCallback(async (audioBlob: Blob): Promise<string | null> => {
    try {
      console.log('üé§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é —á–µ—Ä–µ–∑ OpenAI Whisper...');
      setIsTranscribing(true);

      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');

      const response = await fetch('https://teacher.windexs.ru/api/transcribe', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`
        },
        body: formData
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
        throw new Error(errorData.error || 'Transcription failed');
      }

      const data = await response.json();
      console.log('‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:', data.text);
      return data.text || null;
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:', error);
      toast({
        title: "–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
        variant: "destructive"
      });
      return null;
    } finally {
      setIsTranscribing(false);
    }
  }, [token, toast]);

  // Start fallback recording (MediaRecorder + OpenAI Whisper)
  const startFallbackRecording = useCallback(async () => {
    try {
      console.log('üé§ –ó–∞–ø—É—Å–∫ fallback –∑–∞–ø–∏—Å–∏ (MediaRecorder)...');
      
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        toast({
          title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
          description: "–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ.",
          variant: "destructive"
        });
        return false;
      }

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;
      audioChunksRef.current = [];

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' : 'audio/mp4'
      });
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.start(100); // Collect data every 100ms
      console.log('‚úÖ Fallback –∑–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
      return true;
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ fallback –∑–∞–ø–∏—Å–∏:', error);
      toast({
        title: "–û—à–∏–±–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É.",
        variant: "destructive"
      });
      return false;
    }
  }, [toast]);

  // Stop fallback recording and transcribe
  const stopFallbackRecording = useCallback(async () => {
    return new Promise<string | null>((resolve) => {
      if (!mediaRecorderRef.current) {
        resolve(null);
        return;
      }

      mediaRecorderRef.current.onstop = async () => {
        console.log('üõë Fallback –∑–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, chunks:', audioChunksRef.current.length);
        
        // Stop all tracks
        if (mediaStreamRef.current) {
          mediaStreamRef.current.getTracks().forEach(track => track.stop());
          mediaStreamRef.current = null;
        }

        if (audioChunksRef.current.length === 0) {
          resolve(null);
          return;
        }

        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        audioChunksRef.current = [];

        // Transcribe using OpenAI
        const text = await transcribeWithOpenAI(audioBlob);
        resolve(text);
      };

      mediaRecorderRef.current.stop();
    });
  }, [transcribeWithOpenAI]);

  // Initialize Web Speech API
  const initializeSpeechRecognition = useCallback(() => {
    // Check if Web Speech API is supported (Chrome, Safari, Firefox, Edge)
    const SpeechRecognition = window.SpeechRecognition ||
      (window as any).webkitSpeechRecognition ||
      (window as any).mozSpeechRecognition; // Firefox support

    if (!SpeechRecognition) {
      console.log('‚ö†Ô∏è Web Speech API –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è OpenAI Whisper');
      setUseFallbackTranscription(true);
      return null;
    }

    console.log('üé§ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Web Speech API...');
    const recognition = new SpeechRecognition();

    // Configure recognition
    recognition.continuous = true; // Keep listening continuously
    recognition.interimResults = true; // Enable interim results to detect speech early
    recognition.lang = 'ru-RU'; // Russian language
    recognition.maxAlternatives = 1;

    // Event handlers
    recognition.onstart = () => {
      console.log('üéôÔ∏è Speech recognition started');
      console.log('üéôÔ∏è Recognition —Å–æ—Å—Ç–æ—è–Ω–∏–µ: started');
      setIsTranscribing(true);
    };

    recognition.onspeechstart = () => {
      console.log('üé§ Speech started - stopping assistant speech');
      stopAssistantSpeech();
    };

    // –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –Ω–∞—á–∞–ª–æ —Ä–µ—á–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —ç—Ö–∞
    recognition.onaudiostart = () => {
      // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —á—Ç–æ–±—ã –¥–∞—Ç—å —Å–∏—Å—Ç–µ–º–µ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —ç—Ö–æ–º
      setTimeout(() => {
        if (isPlayingAudioRef.current && speechRecognitionRef.current) {
          console.log('üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —ç—Ö–æ –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –∞—É–¥–∏–æ...');
          // –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞
        }
      }, 100);
    };

    recognition.onresult = async (event) => {
      // Don't process if mic is disabled
      if (!isMicEnabled) {
        console.log('üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç');
        return;
      }

      const result = event.results[event.results.length - 1]; // Get the last result

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º interim —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
      if (!result.isFinal) {
        const interimTranscript = result[0].transcript.trim();


        // –ü–û–ö–ê–ó–´–í–ê–ï–ú –†–ï–ß–¨ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø –ù–ï–ú–ï–î–õ–ï–ù–ù–û
        console.log('üë§ Interim —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:', interimTranscript);

        // –ü–†–ï–†–´–í–ê–ù–ò–ï TTS: –µ—Å–ª–∏ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π TTS –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è
        if (isPlayingAudioRef.current && result[0].confidence > 0.2 && interimTranscript.length > 1) {
          console.log('üõë –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç TTS —Ä–µ—á—å—é:', interimTranscript);
          stopAssistantSpeech();

          // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
          cleanTranscriptRef.current = interimTranscript;

          // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ
          if (speechRecognitionRef.current && isRecording) {
            try {
              speechRecognitionRef.current.stop();
              setIsRecording(false);
              console.log('üé§ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ—Å–ª–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è TTS');
            } catch (e) {
              console.log('‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:', e);
            }
          }
          return; // –ü—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        }

        // –°–æ—Ö—Ä–∞–Ω—è–µ–º interim —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        cleanTranscriptRef.current = interimTranscript;
      }

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
      if (result.isFinal) {
        const transcript = result[0].transcript.trim();
        console.log('üë§ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:', transcript);


        if (transcript) {
          // Stop any current TTS (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ interim)
          if (isSpeaking) {
            console.log('üé§ –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é TTS...');
            stopCurrentTTS();
          }

          // Save current transcript for context
          lastTranscriptRef.current = transcript;

          // Send to LLM and get response
          const llmResponse = await sendToLLM(transcript);

          // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—É—Å—Ç–æ–π –ª–∏ –æ—Ç–≤–µ—Ç (–æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ)
          if (!llmResponse) {
            console.log('üõë –û—Ç–≤–µ—Ç –æ—Ç LLM –ø—É—Å—Ç–æ–π - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±—ã–ª–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞');
            return;
          }

          // Small delay to ensure previous TTS is fully stopped
          await new Promise(resolve => setTimeout(resolve, 100));

          // Speak the response
          await speakText(llmResponse);

          console.log('‚úÖ –û—Ç–≤–µ—Ç –æ–∑–≤—É—á–µ–Ω');
        }
      }
    };

    recognition.onerror = (event) => {
      console.error('‚ùå Speech recognition error:', event.error);
      setIsTranscribing(false);
    };

    recognition.onend = () => {
      console.log('üéôÔ∏è Speech recognition ended');
      setIsTranscribing(false);

      // In continuous mode, onend usually means an error occurred or intentional stop
      // Only restart if we're still in recording state and not speaking (to avoid conflicts)
      if (isRecording && !isSpeaking) {
        console.log('üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø–æ—Å–ª–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏...');
        setTimeout(() => {
          // Double-check we still want to be recording
          if (speechRecognitionRef.current) {
            try {
              speechRecognitionRef.current.start();
              console.log('‚úÖ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —É—Å–ø–µ—à–µ–Ω');
            } catch (e: any) {
              if (e.name !== 'InvalidStateError') {
                console.error('‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞:', e);
              }
            }
          }
        }, 1000); // Longer delay for error recovery
      }
    };

    speechRecognitionRef.current = recognition;
    console.log('‚úÖ Web Speech API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
    return recognition;
  }, [isRecording, isMicEnabled, isSoundEnabled]);

  // Start speech recognition
  const startSpeechRecognition = useCallback(() => {
    if (!speechRecognitionRef.current) {
      console.log('‚ùå Speech recognition –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
      return;
    }

    console.log('üéôÔ∏è –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏...', {
      isRecording,
      isTranscribing,
      recognitionState: speechRecognitionRef.current ? 'exists' : 'null'
    });

    try {
      console.log('üéôÔ∏è –ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏...');
      speechRecognitionRef.current.start();
      console.log('‚úÖ start() –≤—ã–∑–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ');
    } catch (error: any) {
      // Handle "already started" error gracefully
      if (error.name === 'InvalidStateError') {
        console.log('‚ÑπÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º');
        return;
      }
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ speech recognition:', error);
      console.error('‚ùå –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:', {
        message: error.message,
        name: error.name,
        stack: error.stack
      });
      setIsTranscribing(false);
    }
  }, [isRecording, isTranscribing]);

  // Start/stop recording
  const handleStartStopRecording = useCallback(async () => {
    if (isRecording) {
      // Stop recording
      console.log('üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...');
      setIsRecording(false);
      setIsTranscribing(false);

      // Check if using fallback (OpenAI Whisper) mode
      if (useFallbackTranscription || !isWebSpeechAvailable()) {
        // Stop fallback recording and transcribe
        const transcript = await stopFallbackRecording();
        
        if (transcript && transcript.trim()) {
          console.log('üéØ Fallback —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:', transcript);
          
          // Stop any current TTS
          stopCurrentTTS();
          
          // Send to LLM
          try {
            const llmResponse = await sendToLLM(transcript);
            await speakText(llmResponse);
            console.log('‚úÖ –û—Ç–≤–µ—Ç –æ–∑–≤—É—á–µ–Ω');
          } catch (error) {
            console.error('‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞:', error);
          }
        }
      } else {
        // Web Speech API mode
        if (speechRecognitionRef.current) {
          try {
            speechRecognitionRef.current.stop();
          } catch (error) {
            console.log('Speech recognition already stopped');
          }
        }
      }
    } else {
      // Start recording (only if mic is enabled)
      if (!isMicEnabled) {
        toast({
          title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω",
          description: "–í–∫–ª—é—á–∏—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω –¥–ª—è –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏",
          variant: "destructive"
        });
        return;
      }

      console.log('üé§ –ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏...');

      // Check if Web Speech API is available
      if (!isWebSpeechAvailable()) {
        console.log('üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback —Ä–µ–∂–∏–º (OpenAI Whisper)');
        setUseFallbackTranscription(true);
        
        const started = await startFallbackRecording();
        if (started) {
          setIsRecording(true);
          console.log('üé§ Fallback –∑–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
        }
        return;
      }

      try {
        // Initialize Web Speech API if not already done
        if (!speechRecognitionRef.current) {
          const recognition = initializeSpeechRecognition();
          if (!recognition) {
            // Fallback to OpenAI Whisper if Web Speech API fails
            console.log('üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ fallback —Ä–µ–∂–∏–º (OpenAI Whisper)');
            setUseFallbackTranscription(true);
            
            const started = await startFallbackRecording();
            if (started) {
              setIsRecording(true);
              console.log('üé§ Fallback –∑–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
            }
            return;
          }
        }

        setIsRecording(true);

        // Start speech recognition
        startSpeechRecognition();

        console.log('üé§ –ó–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
      } catch (error) {
        console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–ø–∏—Å–∏:', error);
        
        // Try fallback on error
        console.log('üîÑ –û—à–∏–±–∫–∞ Web Speech API, –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ fallback');
        setUseFallbackTranscription(true);
        
        const started = await startFallbackRecording();
        if (started) {
          setIsRecording(true);
        }
      }
    }
  }, [isRecording, isMicEnabled, toast]);

  // Toggle microphone
  const handleToggleMic = useCallback(() => {
    if (isMicEnabled) {
      // Disable mic
      console.log('üé§ –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...');
      setIsMicEnabled(false);
      if (isRecording) {
        // Stop recording if it's active
        setIsRecording(false);
        setIsTranscribing(false);
        
        // Stop Web Speech API if active
        if (speechRecognitionRef.current) {
          try {
            speechRecognitionRef.current.stop();
          } catch (error) {
            console.log('Speech recognition already stopped');
          }
        }
        
        // Stop fallback recording if active
        if (mediaRecorderRef.current) {
          try {
            mediaRecorderRef.current.stop();
          } catch (error) {
            console.log('MediaRecorder already stopped');
          }
        }
        if (mediaStreamRef.current) {
          mediaStreamRef.current.getTracks().forEach(track => track.stop());
          mediaStreamRef.current = null;
        }
      }
      toast({
        title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω",
        description: "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"
      });
    } else {
      // Enable mic
      console.log('üé§ –í–∫–ª—é—á–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...');
      setIsMicEnabled(true);
      toast({
        title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –≤–∫–ª—é—á–µ–Ω",
        description: "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∞–∫—Ç–∏–≤–Ω–æ"
      });
    }
  }, [isMicEnabled, isRecording, toast]);

  // Toggle sound
  const handleToggleSound = useCallback(() => {
    if (isSoundEnabled) {
      // Disable sound
      console.log('üîä –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∑–≤—É–∫–∞...');
      setIsSoundEnabled(false);
      toast({
        title: "–ó–≤—É–∫ –æ—Ç–∫–ª—é—á–µ–Ω",
        description: "–û—Ç–≤–µ—Ç—ã –Ω–µ –±—É–¥—É—Ç –æ–∑–≤—É—á–∏–≤–∞—Ç—å—Å—è"
      });
    } else {
      // Enable sound
      console.log('üîä –í–∫–ª—é—á–µ–Ω–∏–µ –∑–≤—É–∫–∞...');
      setIsSoundEnabled(true);
      toast({
        title: "–ó–≤—É–∫ –≤–∫–ª—é—á–µ–Ω",
        description: "–û—Ç–≤–µ—Ç—ã –±—É–¥—É—Ç –æ–∑–≤—É—á–∏–≤–∞—Ç—å—Å—è"
      });
    }
  }, [isSoundEnabled, toast]);

  // Get user profile from API
  const getUserProfile = useCallback(async () => {
    try {
      const response = await fetch('https://teacher.windexs.ru/api/profile', {
        headers: {
          'Authorization': `Bearer ${token}`
        }
      });

      if (response.ok) {
        const profile = await response.json();
        setUserProfile(profile);
        console.log('üìã –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω:', profile);
        return profile;
      }
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ—Ñ–∏–ª—è:', error);
    }
    return null;
  }, [token]);

  // Get course name from courseId
  const getCourseName = useCallback(() => {
    return getCourseDisplayName(courseId || "");
  }, [courseId]);

  // Send transcribed text to LLM with Julia's system prompt
  const sendToLLM = useCallback(async (userMessage: string): Promise<string> => {
    setIsGeneratingResponse(true);

    // –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º generationId –ø–µ—Ä–µ–¥ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
    const startGenId = generationIdRef.current;

    try {
      console.log('ü§ñ –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ LLM...');

      // Get user profile if not loaded
      let profile = userProfile;
      if (!profile) {
        profile = await getUserProfile();
      }

      // Get course information
      const courseName = getCourseDisplayName(courseId || "");

      // Build context information
      const contextInfo = [];
      if (courseName) {
        contextInfo.push(`–ö—É—Ä—Å: ${courseName}`);
      }
      if (profile) {
        console.log('üìä –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è LLM:', profile);
        if (profile.learning_style) {
          contextInfo.push(`–°—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è: ${profile.learning_style}`);
        }
        if (profile.difficulty_level) {
          contextInfo.push(`–£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: ${profile.difficulty_level}`);
        }
        if (profile.interests) {
          // Safely handle interests - could be string, array, or object
          let interestsStr = '';
          if (typeof profile.interests === 'string') {
            interestsStr = profile.interests;
          } else if (Array.isArray(profile.interests)) {
            interestsStr = profile.interests.join(', ');
          } else if (profile.interests) {
            interestsStr = JSON.stringify(profile.interests);
          }
          if (interestsStr) {
            contextInfo.push(`–ò–Ω—Ç–µ—Ä–µ—Å—ã: ${interestsStr}`);
          }
        }
      }

      const contextString = contextInfo.length > 0 ? `\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:\n${contextInfo.join('\n')}` : '';

      // NOTE:
      // –†–∞–Ω—å—à–µ –º—ã —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª–∏ –∑–¥–µ—Å—å –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º—Ç —É—á–∏—Ç–µ–ª—è –Æ–ª–∏–∏ (teacherJuliaPrompt)
      // –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –µ–≥–æ –∫–∞–∫ content. –¢–µ–ø–µ—Ä—å –≠–¢–û –î–ï–õ–ê–ï–¢ –°–ï–†–í–ï–†:
      //  - —Å–µ—Ä–≤–µ—Ä –∑–Ω–∞–µ—Ç –∫—É—Ä—Å, –ø—Ä–æ—Ñ–∏–ª—å, –¥–æ–º–∞—à–∫–∏
      //  - —Å–∞–º –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç (generateVoiceChatPrompt)
      // –ü–æ—ç—Ç–æ–º—É —Å —Ñ—Ä–æ–Ω—Ç–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û —á–∏—Å—Ç—É—é —Ä–µ–ø–ª–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

      // Prepare message with context if TTS was interrupted
      let messageContent = userMessage;
      if (isSpeaking && lastTranscriptRef.current && lastTranscriptRef.current !== userMessage) {
        // Include previous context when TTS was interrupted
        messageContent = `–ü—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: "${lastTranscriptRef.current}". –ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å: "${userMessage}"`;
        console.log('üìù –ü–µ—Ä–µ–¥–∞—é –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ—Ä–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:', messageContent);
      }

      // Send raw user message to server API
      console.log('üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ VoiceChat:', {
        url: `https://teacher.windexs.ru/api/chat/${courseId}/message`,
        content: messageContent,
        messageType: 'voice',
        token: token ? 'present' : 'missing'
      });

      const response = await fetch(`https://teacher.windexs.ru/api/chat/${courseId}/message`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${token}`
        },
        body: JSON.stringify({
          // –í content –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ.
          // –°–µ—Ä–≤–µ—Ä –ø–æ—Å—Ç—Ä–æ–∏—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç —É—á–∏—Ç–µ–ª—è –Æ–ª–∏–∏ —Å–∞–º.
          content: messageContent,
          messageType: 'voice',
          interrupted: isSpeaking // Flag to indicate if this was an interruption
        })
      });

      if (!response.ok) {
        let errorData = { error: 'Unknown error' };
        try {
          const text = await response.text();
          if (text) {
            errorData = JSON.parse(text);
          }
        } catch (parseError) {
          console.error('‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞:', parseError);
        }
        console.error('‚ùå –û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞ —Å –æ—à–∏–±–∫–æ–π:', response.status, errorData);
        throw new Error(errorData.error || 'Failed to get LLM response');
      }

      // Parse response safely
      let data;
      try {
        const text = await response.text();
        console.log('üì• –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞:', text.substring(0, 200));
        data = JSON.parse(text);
      } catch (parseError) {
        console.error('‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON:', parseError);
        throw new Error('Invalid JSON response from server');
      }

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–æ –ª–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
      if (generationIdRef.current !== startGenId) {
        console.log('üõë –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –±—ã–ª–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞');
        return '';
      }

      console.log('‚úÖ LLM –æ—Ç–≤–µ—Ç–∏–ª:', data.message);

      return data.message || '–ò–∑–≤–∏–Ω–∏, —è –Ω–µ —Å–º–æ–≥–ª–∞ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.';

    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ LLM:', error);
      console.error('‚ùå –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:', {
        message: error.message,
        stack: error.stack,
        name: error.name
      });
      return '–ò–∑–≤–∏–Ω–∏, —É –º–µ–Ω—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–µ–ø–æ–ª–∞–¥–∫–∏. –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É.';
    } finally {
      setIsGeneratingResponse(false);
    }
  }, [token, userProfile, courseId, getUserProfile]);





// –û—á–∏—Å—Ç–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è TTS
  const clearTTSState = useCallback(() => {
    currentTTSTextRef.current = '';
    setIsSpeaking(false);
  }, []);

  // Convert text to speech using OpenAI TTS
  const speakText = useCallback(async (text: string) => {
    // Don't speak if sound is disabled
    if (!isSoundEnabled) {
      console.log('üîá –ó–≤—É–∫ –æ—Ç–∫–ª—é—á–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–∑–≤—É—á–∫—É');
      return;
    }

    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
    isPlayingAudioRef.current = true;
    // Store the TTS text for echo detection
    currentTTSTextRef.current = text;

    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —ç—Ö–∞
    const normalizedText = text.toLowerCase().replace(/[^\w\s]/g, '').replace(/\s+/g, ' ').trim();
    const words = normalizedText.split(/\s+/).filter(w => w.length > 0);
    const estimatedDuration = words.length * 150; // ~150–º—Å –Ω–∞ —Å–ª–æ–≤–æ

    ttsProgressRef.current = {
      startTime: Date.now(),
      text: normalizedText,
      duration: estimatedDuration,
      words: words,
      currentWordIndex: 0
    };

    setIsSpeaking(true);


    // –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º generationId –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
    const myGenId = generationIdRef.current;

    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–æ –ª–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –ø–µ—Ä–µ–¥ —Å–∏–Ω—Ç–µ–∑–æ–º
      if (generationIdRef.current !== myGenId) {
        console.log('üõë –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –±—ã–ª –æ—Ç–º–µ–Ω–µ–Ω');
        return;
      }

      console.log('üîä –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤ OpenAI TTS...');

      const response = await fetch('https://teacher.windexs.ru/api/tts', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${token}`
        },
        body: JSON.stringify({
          text: text,
          voice: 'nova' // High-quality educational voice (HD model)
        })
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
        throw new Error(errorData.error || 'Failed to generate speech');
      }

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–æ –ª–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
      if (generationIdRef.current !== myGenId) {
        console.log('üõë –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –±—ã–ª –æ—Ç–º–µ–Ω–µ–Ω –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –∞—É–¥–∏–æ');
        return;
      }

      // Get audio blob
      const audioBlob = await response.blob();
      console.log('‚úÖ –ü–æ–ª—É—á–µ–Ω –∞—É–¥–∏–æ —Ñ–∞–π–ª, —Ä–∞–∑–º–µ—Ä:', audioBlob.size);


      // –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –∞—É–¥–∏–æ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –Ω–æ–≤–æ–≥–æ
      // –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–ª–æ–∂–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö TTS –ø–æ—Ç–æ–∫–æ–≤
      if (currentAudioRef.current) {
        stopCurrentTTS();
      }

      // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –∞—É–¥–∏–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ
      await new Promise(resolve => setTimeout(resolve, 100));

      // Create audio element and play
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      currentAudioRef.current = audio;

      // Event handlers
      audio.onplay = () => {
        console.log('üîä –û–∑–≤—É—á–∫–∞ –Ω–∞—á–∞—Ç–∞');
      };

      audio.onended = () => {
        console.log('‚úÖ –û–∑–≤—É—á–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞');
        URL.revokeObjectURL(audioUrl);
        currentAudioRef.current = null;
        isPlayingAudioRef.current = false;
        setIsSpeaking(false);
        // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
        ttsProgressRef.current = null;
      };

      audio.onerror = (event) => {
        console.error('‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ:', event);
        URL.revokeObjectURL(audioUrl);
        currentAudioRef.current = null;
        setIsSpeaking(false);
        // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
        ttsProgressRef.current = null;

        // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        if (speechRecognitionRef.current && isRecording) {
          try {
            speechRecognitionRef.current.stop();
            setIsRecording(false);
          } catch (e) {
            console.log('‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ TTS:', e);
          }
        }
        toast({
          title: "–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏",
          description: "–ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –∞—É–¥–∏–æ",
          variant: "destructive"
        });
      };

      // Small delay to ensure clean start
      await new Promise(resolve => setTimeout(resolve, 50));

      // Start playing
      await audio.play();

    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ TTS:', error);
      setIsSpeaking(false);

      // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
      if (speechRecognitionRef.current && isRecording) {
        try {
          speechRecognitionRef.current.stop();
          setIsRecording(false);
        } catch (e) {
          console.log('‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ TTS:', e);
        }
      }

      toast({
        title: "–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏",
        description: `–ù–µ —É–¥–∞–ª–æ—Å—å –æ–∑–≤—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç: ${error.message}`,
        variant: "destructive"
      });
    }
  }, [token, toast, isSoundEnabled, stopCurrentTTS]);


  // Load user profile on component mount
  useEffect(() => {
    if (token) {
      getUserProfile();
    }
  }, [token, getUserProfile]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      console.log('üßπ –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏');
      // Stop Web Speech API
      if (speechRecognitionRef.current) {
        try {
          speechRecognitionRef.current.stop();
        } catch (error) {
          // Already stopped
        }
      }
      // Stop fallback MediaRecorder
      if (mediaRecorderRef.current) {
        try {
          mediaRecorderRef.current.stop();
        } catch (error) {
          // Already stopped
        }
      }
      // Stop media stream
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach(track => track.stop());
      }
      // Stop current TTS and monitoring
      stopAssistantSpeech();
      // Stop speech synthesis (fallback)
      if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel();
      }
      // Close audio context
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close();
      }
    };
  }, []);

  return (
    <div className="min-h-screen bg-background">
      <Navigation />


      <main className="container mx-auto px-4 pt-24 pb-16">
        <div className="max-w-2xl mx-auto">
          <div className="text-center mb-8 animate-fade-in">
            <h1 className="text-3xl md:text-4xl font-bold mb-4 bg-gradient-to-r from-primary to-emerald-600 bg-clip-text text-transparent">
              –ì–æ–ª–æ—Å–æ–≤–æ–µ –æ–±—â–µ–Ω–∏–µ
            </h1>
            <p className="text-muted-foreground">
              {getCourseDisplayName(courseId || "")}
            </p>
          </div>

          <Card className="shadow-2xl animate-fade-in">
            <CardContent className="p-8 md:p-12">
              <div className="text-center space-y-6">
                {/* Status Indicator */}
                <div className="relative inline-block">
                  <div className={`w-32 h-32 md:w-40 md:h-40 rounded-full ${
                    isRecording ? 'bg-green-500/20' : 'bg-muted'
                  } flex items-center justify-center transition-all duration-300`}>
                    <Mic className={`w-16 h-16 md:w-20 md:h-20 ${
                      isRecording ? 'text-green-500' : 'text-muted-foreground'
                    }`} />
                  </div>
                  {isRecording && (
                    <div className="absolute inset-0 rounded-full animate-ping bg-green-500/20"></div>
                  )}
                </div>

                {/* Status Text */}
                <div>
                  <h2 className="text-2xl font-bold mb-2">
                    {isRecording ? "–ò–¥–µ—Ç –∑–∞–ø–∏—Å—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ" : "–ì–æ—Ç–æ–≤ –∫ –∑–∞–ø–∏—Å–∏"}
                  </h2>
                  <p className="text-muted-foreground mb-3">
                    {isRecording
                      ? "–ì–æ–≤–æ—Ä–∏—Ç–µ —Å–≤–æ–±–æ–¥–Ω–æ - —Ç–µ–∫—Å—Ç –≤—ã–≤–æ–¥–∏—Ç—Å—è –≤ –∫–æ–Ω—Å–æ–ª—å"
                      : "–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –¥–ª—è –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏"
                    }
                  </p>

                  {/* Recording Status */}
                  <div className="flex flex-wrap justify-center gap-2">
                    {isRecording && (
                      <Badge variant="secondary" className="bg-green-100 text-green-700 border-green-200 animate-pulse">
                        üé§ {useFallbackTranscription ? '–ó–∞–ø–∏—Å—å (OpenAI)...' : '–ó–∞–ø–∏—Å—å –∞–∫—Ç–∏–≤–Ω–∞...'}
                      </Badge>
                    )}
                    {isTranscribing && (
                      <Badge variant="outline" className="bg-blue-50 text-blue-700 border-blue-200">
                        <Loader2 className="w-3 h-3 mr-1 animate-spin" />
                        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...
                      </Badge>
                    )}
                    {isGeneratingResponse && (
                      <Badge variant="outline" className="bg-purple-50 text-purple-700 border-purple-200">
                        <Loader2 className="w-3 h-3 mr-1 animate-spin" />
                        ü§ñ –î—É–º–∞—é...
                      </Badge>
                    )}
                    {isSpeaking && (
                      <Badge variant="outline" className="bg-orange-50 text-orange-700 border-orange-200 animate-pulse">
                        üîä –ì–æ–≤–æ—Ä—é...
                      </Badge>
                    )}
                    {!isRecording && (
                      <Badge variant="outline" className="bg-gray-50 text-gray-700 border-gray-200">
                        üîá –û–∂–∏–¥–∞–Ω–∏–µ –Ω–∞—á–∞–ª–∞
                      </Badge>
                    )}
                  </div>
                </div>

                {/* Control Buttons */}
                <div className="flex flex-wrap justify-center gap-4">
                  <Button
                    variant="outline"
                    size="lg"
                    className={`w-16 h-16 rounded-full ${isMicEnabled ? 'bg-green-50 border-green-200 hover:bg-green-100' : 'bg-red-50 border-red-200 hover:bg-red-100'}`}
                    onClick={handleToggleMic}
                    title={isMicEnabled ? "–û—Ç–∫–ª—é—á–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω" : "–í–∫–ª—é—á–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω"}
                  >
                    {isMicEnabled ? (
                      <Mic className="w-6 h-6 text-green-600" />
                    ) : (
                      <MicOff className="w-6 h-6 text-red-600" />
                    )}
                  </Button>
                  <Button
                    variant="outline"
                    size="lg"
                    className={`w-16 h-16 rounded-full ${isSoundEnabled ? 'bg-blue-50 border-blue-200 hover:bg-blue-100' : 'bg-gray-50 border-gray-200 hover:bg-gray-100'}`}
                    onClick={handleToggleSound}
                    title={isSoundEnabled ? "–û—Ç–∫–ª—é—á–∏—Ç—å –∑–≤—É–∫" : "–í–∫–ª—é—á–∏—Ç—å –∑–≤—É–∫"}
                  >
                    {isSoundEnabled ? (
                      <Volume2 className="w-6 h-6 text-blue-600" />
                    ) : (
                      <VolumeX className="w-6 h-6 text-gray-600" />
                    )}
                  </Button>
                </div>

                {/* Main Action Button */}
                <Button
                  size="lg"
                  className={`w-full max-w-xs h-14 text-lg ${isRecording ? 'bg-red-500 hover:bg-red-600' : ''}`}
                  onClick={handleStartStopRecording}
                >
                  {isRecording ? (
                    <>
                      <PhoneOff className="w-5 h-5 mr-2" />
                      –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å
                    </>
                  ) : (
                    <>
                      <Phone className="w-5 h-5 mr-2" />
                      –ù–∞—á–∞—Ç—å —É—Ä–æ–∫
                    </>
                  )}
                </Button>
              </div>
            </CardContent>
          </Card>

        </div>
      </main>
    </div>
  );
};

export default VoiceChat;
