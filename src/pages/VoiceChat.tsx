import Navigation from "@/components/Navigation";
import { useParams, useNavigate } from "react-router-dom";
import { getCourseDisplayName } from "@/lib/utils";
import { Mic, MicOff, Volume2, VolumeX, Phone, PhoneOff, Loader2, ArrowLeft } from "lucide-react";
import { Button } from "@/components/ui/button";
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import { useState, useRef, useCallback, useEffect, useMemo } from "react";
import { useAuth } from "@/contexts/AuthContext";
import { useToast } from "@/hooks/use-toast";
import { monitorLLMRequest, monitorLLMResponse, isSuspiciousMessage, generateSafeAlternative, generateSuperSafePhrase, updateLearnedAlternatives } from "@/utils/llmMonitoring";
import AssistantOrb from "@/components/AssistantOrb";
import BackgroundStars from "@/components/BackgroundStars";

// Web Speech API types

// –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≥–æ–ª–æ—Å–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —ç—Ö–∞
const VOICE_DETECTION_THRESHOLD = 15; // –ë–∞–∑–æ–≤—ã–π –ø–æ—Ä–æ–≥ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –≥–æ–ª–æ—Å–∞
const ECHO_SIMILARITY_THRESHOLD = 0.7; // –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç—Ö–∞
const ECHO_BUFFER_TIME = 500; // –í—Ä–µ–º—è –≤ –º—Å –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª–∞ TTS, –∫–æ–≥–¥–∞ —ç—Ö–æ –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ

// –ú–æ–¥–µ–ª—å LLM –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞
const VOICE_CHAT_LLM_MODEL = 'gpt-5.1'; // GPT-5.1 –¥–ª—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message?: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((event: Event) => void) | null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;
  onend: ((event: Event) => void) | null;
}

declare global {
  interface Window {
    SpeechRecognition?: new () => SpeechRecognition;
    webkitSpeechRecognition?: new () => SpeechRecognition;
    mozSpeechRecognition?: new () => SpeechRecognition; // Firefox support
  }
}

const VoiceChat = () => {
  const { courseId } = useParams();
  const navigate = useNavigate();
  const { token } = useAuth();
  const { toast } = useToast();

  const [isRecording, setIsRecording] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [isGeneratingResponse, setIsGeneratingResponse] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isMicEnabled, setIsMicEnabled] = useState(true);
  const [isSoundEnabled, setIsSoundEnabled] = useState(true);
  const [userProfile, setUserProfile] = useState<any>(null);
  const [useFallbackTranscription, setUseFallbackTranscription] = useState(false);
  const [transcriptDisplay, setTranscriptDisplay] = useState<string>("");

  const speechRecognitionRef = useRef<SpeechRecognition | null>(null);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);
  const lastTranscriptRef = useRef<string>('');
  const cleanTranscriptRef = useRef<string>(''); // Track clean transcript without TTS echo
  const currentTTSTextRef = useRef<string>(''); // Store current TTS text to detect echo

  // –ú–µ—Ö–∞–Ω–∏–∑–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–º–µ–Ω—ã –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏
  const generationIdRef = useRef<number>(0);

  // –ê—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
  const audioContextRef = useRef<AudioContext | null>(null);
  const audioAnalyserRef = useRef<AnalyserNode | null>(null);
  const microphoneSourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const volumeMonitorRef = useRef<number | null>(null);

  // –°–æ—Å—Ç–æ—è–Ω–∏–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ
  const isPlayingAudioRef = useRef<boolean>(false);

  // –û—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
  const audioQueueRef = useRef<ArrayBuffer[]>([]);

  // –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–∑–≤—É—á–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —ç—Ö–∞
  const ttsProgressRef = useRef<{
    startTime: number;
    text: string;
    duration: number; // –ø—Ä–∏–º–µ—Ä–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –º—Å
    words: string[]; // —Å–ª–æ–≤–∞ –ø–æ –ø–æ—Ä—è–¥–∫—É
    currentWordIndex: number;
  } | null>(null);

  // Fallback recording refs (for browsers without Web Speech API)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const mediaStreamRef = useRef<MediaStream | null>(null);


  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
  const initializeAudioContext = useCallback(async (): Promise<AudioContext> => {
    if (audioContextRef.current) {
      return audioContextRef.current;
    }

    const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
    audioContextRef.current = new AudioContextClass();

    // Resume context if suspended (required by some browsers)
    if (audioContextRef.current.state === 'suspended') {
      await audioContextRef.current.resume();
    }

    return audioContextRef.current;
  }, []);

  // –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
  const stopAssistantSpeech = useCallback(() => {
    console.log('üõë –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Ä–µ—á—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞');

    // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º generationId –¥–ª—è –æ—Ç–º–µ–Ω—ã —Ç–µ–∫—É—â–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    generationIdRef.current += 1;

    // –û—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å –∞—É–¥–∏–æ
    audioQueueRef.current = [];

    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
    if (currentAudioRef.current) {
      try {
        currentAudioRef.current.pause();
        currentAudioRef.current.currentTime = 0;
        currentAudioRef.current.volume = 0;
        currentAudioRef.current.muted = true;
        currentAudioRef.current.src = '';
        currentAudioRef.current.load();
      } catch (error) {
        console.warn('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∞—É–¥–∏–æ:', error);
      }
      currentAudioRef.current = null;
    }


    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    isPlayingAudioRef.current = false;
    setIsSpeaking(false);

    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
    ttsProgressRef.current = null;
  }, []);

  // Function to stop current TTS playback
  const stopCurrentTTS = useCallback(() => {
    stopAssistantSpeech();
  }, []);

  // Check if Web Speech API is available
  const isWebSpeechAvailable = useCallback(() => {
    const SpeechRecognition = window.SpeechRecognition ||
      (window as any).webkitSpeechRecognition ||
      (window as any).mozSpeechRecognition;
    return !!SpeechRecognition;
  }, []);

  // Transcribe audio using OpenAI Whisper API (fallback for browsers without Web Speech API)
  const transcribeWithOpenAI = useCallback(async (audioBlob: Blob): Promise<string | null> => {
    try {
      console.log('üé§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é —á–µ—Ä–µ–∑ OpenAI Whisper...');
      setIsTranscribing(true);

      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');

      const response = await fetch('https://teacher.windexs.ru/api/transcribe', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`
        },
        body: formData
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
        throw new Error(errorData.error || 'Transcription failed');
      }

      const data = await response.json();
      console.log('‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:', data.text);
      return data.text || null;
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:', error);
      toast({
        title: "–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
        variant: "destructive"
      });
      return null;
    } finally {
      setIsTranscribing(false);
    }
  }, [token, toast]);

  // Start fallback recording (MediaRecorder + OpenAI Whisper)
  const startFallbackRecording = useCallback(async () => {
    try {
      console.log('üé§ –ó–∞–ø—É—Å–∫ fallback –∑–∞–ø–∏—Å–∏ (MediaRecorder)...');

      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        toast({
          title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
          description: "–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ.",
          variant: "destructive"
        });
        return false;
      }

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;
      audioChunksRef.current = [];

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' : 'audio/mp4'
      });
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.start(100); // Collect data every 100ms
      console.log('‚úÖ Fallback –∑–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
      return true;
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ fallback –∑–∞–ø–∏—Å–∏:', error);
      toast({
        title: "–û—à–∏–±–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É.",
        variant: "destructive"
      });
      return false;
    }
  }, [toast]);

  // Stop fallback recording and transcribe
  const stopFallbackRecording = useCallback(async () => {
    return new Promise<string | null>((resolve) => {
      if (!mediaRecorderRef.current) {
        resolve(null);
        return;
      }

      mediaRecorderRef.current.onstop = async () => {
        console.log('üõë Fallback –∑–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, chunks:', audioChunksRef.current.length);

        // Stop all tracks
        if (mediaStreamRef.current) {
          mediaStreamRef.current.getTracks().forEach(track => track.stop());
          mediaStreamRef.current = null;
        }

        if (audioChunksRef.current.length === 0) {
          resolve(null);
          return;
        }

        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        audioChunksRef.current = [];

        // Transcribe using OpenAI
        const text = await transcribeWithOpenAI(audioBlob);
        resolve(text);
      };

      mediaRecorderRef.current.stop();
    });
  }, [transcribeWithOpenAI]);

  // Initialize Web Speech API
  const initializeSpeechRecognition = useCallback(() => {
    // Check if Web Speech API is supported (Chrome, Safari, Firefox, Edge)
    const SpeechRecognition = window.SpeechRecognition ||
      (window as any).webkitSpeechRecognition ||
      (window as any).mozSpeechRecognition; // Firefox support

    if (!SpeechRecognition) {
      console.log('‚ö†Ô∏è Web Speech API –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è OpenAI Whisper');
      setUseFallbackTranscription(true);
      return null;
    }

    console.log('üé§ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Web Speech API...');
    const recognition = new SpeechRecognition();

    // Configure recognition
    recognition.continuous = true; // Keep listening continuously
    recognition.interimResults = true; // Enable interim results to detect speech early
    recognition.lang = 'ru-RU'; // Russian language
    recognition.maxAlternatives = 1;

    // Event handlers
    recognition.onstart = () => {
      console.log('üéôÔ∏è Speech recognition started');
      console.log('üéôÔ∏è Recognition —Å–æ—Å—Ç–æ—è–Ω–∏–µ: started');
      setIsTranscribing(true);
    };

    recognition.onspeechstart = () => {
      console.log('üé§ Speech started - IMMEDIATELY stopping assistant speech');
      // –ü—Ä–µ—Ä—ã–≤–∞–µ–º TTS –ù–ï–ú–ï–î–õ–ï–ù–ù–û –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –ª—é–±–æ–π —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
      stopAssistantSpeech();
    };

    // –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –Ω–∞—á–∞–ª–æ —Ä–µ—á–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —ç—Ö–∞
    recognition.onaudiostart = () => {
      // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —á—Ç–æ–±—ã –¥–∞—Ç—å —Å–∏—Å—Ç–µ–º–µ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —ç—Ö–æ–º
      setTimeout(() => {
        if (isPlayingAudioRef.current && speechRecognitionRef.current) {
          console.log('üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —ç—Ö–æ –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –∞—É–¥–∏–æ...');
          // –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞
        }
      }, 100);
    };

    recognition.onresult = async (event) => {
      // Don't process if mic is disabled
      if (!isMicEnabled) {
        console.log('üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç');
        return;
      }

      const result = event.results[event.results.length - 1]; // Get the last result

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º interim —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
      if (!result.isFinal) {
        const interimTranscript = result[0].transcript.trim();
        setTranscriptDisplay(interimTranscript);

        // –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ï –ü–†–ï–†–´–í–ê–ù–ò–ï: –ø—Ä–µ—Ä—ã–≤–∞–µ–º TTS –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –ª—é–±–æ–π —Ä–µ—á–µ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        if (isPlayingAudioRef.current) {
          console.log('üö® –†–µ—á–µ–≤–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ - –ù–ï–ú–ï–î–õ–ï–ù–ù–û –ø—Ä–µ—Ä—ã–≤–∞–µ–º TTS');
          console.log('üõë –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ TTS –∏–∑-–∑–∞ —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è');
          stopAssistantSpeech();
        }

        // –ü–û–ö–ê–ó–´–í–ê–ï–ú –†–ï–ß–¨ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø –ù–ï–ú–ï–î–õ–ï–ù–ù–û
        console.log('üë§ Interim —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:', interimTranscript);

        // –ü–†–ï–†–´–í–ê–ù–ò–ï TTS: –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–∏ –õ–Æ–ë–û–ô —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –¥–∞–∂–µ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        if (isPlayingAudioRef.current && interimTranscript.length > 0) {
          console.log('üõë –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç TTS —Ä–µ—á—å—é (–¥–∞–∂–µ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é):', interimTranscript, `(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: ${result[0].confidence})`);

          // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –∫–æ–º–∞–Ω–¥–æ–π –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
          const interruptCommands = ['–ø–æ–¥–æ–∂–¥–∏', '—Å—Ç–æ–ø', '–ø—Ä–µ–∫—Ä–∞—Ç–∏', '–ø–µ—Ä–µ—Å—Ç–∞–Ω—å', '—Ö–≤–∞—Ç–∏—Ç', '—Ç–∏—Ö–æ', '–º–æ–ª—á–∞—Ç—å', '–∑–∞–º–æ–ª—á–∏', 'stop', 'wait'];
          const isInterruptCommand = interruptCommands.some(cmd =>
            interimTranscript.toLowerCase().includes(cmd)
          );

          if (isInterruptCommand) {
            console.log('üö® –ö–æ–º–∞–Ω–¥–∞ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞:', interimTranscript);
          }

          stopAssistantSpeech();

          // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
          cleanTranscriptRef.current = interimTranscript;

          // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ
          if (speechRecognitionRef.current && isRecording) {
            try {
              speechRecognitionRef.current.stop();
              setIsRecording(false);
              console.log('üé§ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ—Å–ª–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è TTS');
            } catch (e) {
              console.log('‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:', e);
            }
          }
          return; // –ü—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        }

        // –°–æ—Ö—Ä–∞–Ω—è–µ–º interim —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        cleanTranscriptRef.current = interimTranscript;
      }

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
      if (result.isFinal) {
        const transcript = result[0].transcript.trim();
        setTranscriptDisplay(transcript);
        console.log('üë§ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:', transcript);

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –∫–æ–º–∞–Ω–¥–æ–π –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
        const interruptCommands = ['–ø–æ–¥–æ–∂–¥–∏', '—Å—Ç–æ–ø', '–ø—Ä–µ–∫—Ä–∞—Ç–∏', '–ø–µ—Ä–µ—Å—Ç–∞–Ω—å', '—Ö–≤–∞—Ç–∏—Ç', '—Ç–∏—Ö–æ', '–º–æ–ª—á–∞—Ç—å', '–∑–∞–º–æ–ª—á–∏', 'stop', 'wait'];
        const isInterruptCommand = interruptCommands.some(cmd =>
          transcript.toLowerCase().includes(cmd)
        );

        if (transcript) {
          // Stop any current TTS (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ interim)
          if (isSpeaking) {
            console.log('üé§ –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é TTS...');
            stopCurrentTTS();
          }

          // –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
          if (isInterruptCommand) {
            console.log('üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ:', transcript);
            toast({
              title: "–ì–æ—Ç–æ–≤–æ",
              description: "–û–∑–≤—É—á–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞",
              variant: "default"
            });
            return; // –ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ LLM
          }

          // Save current transcript for context
          lastTranscriptRef.current = transcript;

          // Send to LLM and get response
          const llmResponse = await sendToLLM(transcript);

          // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—É—Å—Ç–æ–π –ª–∏ –æ—Ç–≤–µ—Ç (–æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ)
          if (!llmResponse) {
            console.log('üõë –û—Ç–≤–µ—Ç –æ—Ç LLM –ø—É—Å—Ç–æ–π - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±—ã–ª–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞');
            return;
          }

          // Small delay to ensure previous TTS is fully stopped
          await new Promise(resolve => setTimeout(resolve, 100));

          // Speak the response (only if not empty)
          if (llmResponse && llmResponse.trim()) {
            await speakText(llmResponse);
          } else {
            console.warn('‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞');
          }

          console.log('‚úÖ –û—Ç–≤–µ—Ç –æ–∑–≤—É—á–µ–Ω');
        }
      }
    };

    recognition.onerror = (event) => {
      console.error('‚ùå Speech recognition error:', event.error);
      setIsTranscribing(false);
    };

    recognition.onend = () => {
      console.log('üéôÔ∏è Speech recognition ended');
      setIsTranscribing(false);

      // In continuous mode, onend usually means an error occurred or intentional stop
      // Only restart if we're still in recording state and not speaking (to avoid conflicts)
      if (isRecording && !isSpeaking) {
        console.log('üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø–æ—Å–ª–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏...');
        setTimeout(() => {
          // Double-check we still want to be recording
          if (speechRecognitionRef.current) {
            try {
              speechRecognitionRef.current.start();
              console.log('‚úÖ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —É—Å–ø–µ—à–µ–Ω');
            } catch (e: any) {
              if (e.name !== 'InvalidStateError') {
                console.error('‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞:', e);
              }
            }
          }
        }, 1000); // Longer delay for error recovery
      }
    };

    speechRecognitionRef.current = recognition;
    console.log('‚úÖ Web Speech API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
    return recognition;
  }, [isRecording, isMicEnabled, isSoundEnabled]);

  // Start speech recognition
  const startSpeechRecognition = useCallback(() => {
    if (!speechRecognitionRef.current) {
      console.log('‚ùå Speech recognition –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
      return;
    }

    console.log('üéôÔ∏è –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏...', {
      isRecording,
      isTranscribing,
      recognitionState: speechRecognitionRef.current ? 'exists' : 'null'
    });

    try {
      console.log('üéôÔ∏è –ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏...');
      speechRecognitionRef.current.start();
      console.log('‚úÖ start() –≤—ã–∑–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ');
    } catch (error: any) {
      // Handle "already started" error gracefully
      if (error.name === 'InvalidStateError') {
        console.log('‚ÑπÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º');
        return;
      }
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ speech recognition:', error);
      console.error('‚ùå –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:', {
        message: error.message,
        name: error.name,
        stack: error.stack
      });
      setIsTranscribing(false);
    }
  }, [isRecording, isTranscribing]);

  // Start/stop recording
  const handleStartStopRecording = useCallback(async () => {
    if (isRecording) {
      // Stop recording
      console.log('üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...');
      setIsRecording(false);
      setIsTranscribing(false);

      // Check if using fallback (OpenAI Whisper) mode
      if (useFallbackTranscription || !isWebSpeechAvailable()) {
        // Stop fallback recording and transcribe
        const transcript = await stopFallbackRecording();

        if (transcript && transcript.trim()) {
          console.log('üéØ Fallback —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:', transcript);
          setTranscriptDisplay(transcript);

          // Stop any current TTS
          stopCurrentTTS();

          // Send to LLM
          try {
            const llmResponse = await sendToLLM(transcript);
            if (llmResponse && llmResponse.trim()) {
              await speakText(llmResponse);
              console.log('‚úÖ –û—Ç–≤–µ—Ç –æ–∑–≤—É—á–µ–Ω');
            } else {
              console.warn('‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞');
            }
          } catch (error) {
            console.error('‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞:', error);
          }
        }
      } else {
        // Web Speech API mode
        if (speechRecognitionRef.current) {
          try {
            speechRecognitionRef.current.stop();
          } catch (error) {
            console.log('Speech recognition already stopped');
          }
        }
      }
    } else {
      // Start recording (only if mic is enabled)
      if (!isMicEnabled) {
        toast({
          title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω",
          description: "–í–∫–ª—é—á–∏—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω –¥–ª—è –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏",
          variant: "destructive"
        });
        return;
      }

      console.log('üé§ –ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏...');
      setTranscriptDisplay("");

      // Check if Web Speech API is available
      if (!isWebSpeechAvailable()) {
        console.log('üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback —Ä–µ–∂–∏–º (OpenAI Whisper)');
        setUseFallbackTranscription(true);

        const started = await startFallbackRecording();
        if (started) {
          setIsRecording(true);
          console.log('üé§ Fallback –∑–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
        }
        return;
      }

      try {
        // Initialize Web Speech API if not already done
        if (!speechRecognitionRef.current) {
          const recognition = initializeSpeechRecognition();
          if (!recognition) {
            // Fallback to OpenAI Whisper if Web Speech API fails
            console.log('üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ fallback —Ä–µ–∂–∏–º (OpenAI Whisper)');
            setUseFallbackTranscription(true);

            const started = await startFallbackRecording();
            if (started) {
              setIsRecording(true);
              console.log('üé§ Fallback –∑–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
            }
            return;
          }
        }

        setIsRecording(true);

        // Start speech recognition
        startSpeechRecognition();

        console.log('üé§ –ó–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞');
      } catch (error) {
        console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–ø–∏—Å–∏:', error);

        // Try fallback on error
        console.log('üîÑ –û—à–∏–±–∫–∞ Web Speech API, –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ fallback');
        setUseFallbackTranscription(true);

        const started = await startFallbackRecording();
        if (started) {
          setIsRecording(true);
        }
      }
    }
  }, [isRecording, isMicEnabled, toast]);

  // Toggle microphone
  const handleToggleMic = useCallback(() => {
    if (isMicEnabled) {
      // Disable mic
      console.log('üé§ –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...');
      setIsMicEnabled(false);
      if (isRecording) {
        // Stop recording if it's active
        setIsRecording(false);
        setIsTranscribing(false);

        // Stop Web Speech API if active
        if (speechRecognitionRef.current) {
          try {
            speechRecognitionRef.current.stop();
          } catch (error) {
            console.log('Speech recognition already stopped');
          }
        }

        // Stop fallback recording if active
        if (mediaRecorderRef.current) {
          try {
            mediaRecorderRef.current.stop();
          } catch (error) {
            console.log('MediaRecorder already stopped');
          }
        }
        if (mediaStreamRef.current) {
          mediaStreamRef.current.getTracks().forEach(track => track.stop());
          mediaStreamRef.current = null;
        }
      }
      toast({
        title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω",
        description: "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ"
      });
    } else {
      // Enable mic
      console.log('üé§ –í–∫–ª—é—á–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...');
      setIsMicEnabled(true);
      toast({
        title: "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –≤–∫–ª—é—á–µ–Ω",
        description: "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∞–∫—Ç–∏–≤–Ω–æ"
      });
    }
  }, [isMicEnabled, isRecording, toast]);

  // Toggle sound
  const handleToggleSound = useCallback(() => {
    if (isSoundEnabled) {
      // Disable sound
      console.log('üîä –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∑–≤—É–∫–∞...');
      setIsSoundEnabled(false);
      toast({
        title: "–ó–≤—É–∫ –æ—Ç–∫–ª—é—á–µ–Ω",
        description: "–û—Ç–≤–µ—Ç—ã –Ω–µ –±—É–¥—É—Ç –æ–∑–≤—É—á–∏–≤–∞—Ç—å—Å—è"
      });
    } else {
      // Enable sound
      console.log('üîä –í–∫–ª—é—á–µ–Ω–∏–µ –∑–≤—É–∫–∞...');
      setIsSoundEnabled(true);
      toast({
        title: "–ó–≤—É–∫ –≤–∫–ª—é—á–µ–Ω",
        description: "–û—Ç–≤–µ—Ç—ã –±—É–¥—É—Ç –æ–∑–≤—É—á–∏–≤–∞—Ç—å—Å—è"
      });
    }
  }, [isSoundEnabled, toast]);

  // Get user profile from API
  const getUserProfile = useCallback(async () => {
    try {
      const response = await fetch('https://teacher.windexs.ru/api/profile', {
        headers: {
          'Authorization': `Bearer ${token}`
        }
      });

      if (response.ok) {
        const profile = await response.json();
        setUserProfile(profile);
        console.log('üìã –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω:', profile);
        return profile;
      }
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ—Ñ–∏–ª—è:', error);
    }
    return null;
  }, [token]);

  // Get course name from courseId
  const getCourseName = useCallback(() => {
    return getCourseDisplayName(courseId || "");
  }, [courseId]);

  // Send transcribed text to LLM with Julia's system prompt
  const sendToLLM = useCallback(async (userMessage: string, retryCount: number = 0): Promise<string> => {
    const MAX_RETRIES = 3; // –£–≤–µ–ª–∏—á–∏–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
    const originalMessage = userMessage;

    console.log('üöÄ sendToLLM –≤—ã–∑–≤–∞–Ω–∞ —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º:', `"${userMessage}"`, retryCount > 0 ? `(–ø–æ–ø—ã—Ç–∫–∞ ${retryCount + 1}/${MAX_RETRIES + 1})` : '');
    console.log('üìè –î–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è:', userMessage.length);
    console.log('ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å:', VOICE_CHAT_LLM_MODEL);

    setIsGeneratingResponse(true);

    // –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º generationId –ø–µ—Ä–µ–¥ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
    const startGenId = generationIdRef.current;

    try {
      console.log('ü§ñ –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ LLM...');

      // –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
      // monitorLLMRequest(userMessage, courseId || 'unknown');

      // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–¥–ª—è –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫, –Ω–æ —Å —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏)
      // if (isSuspiciousMessage(userMessage)) {
      //   console.warn('‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:', userMessage);
      //   const safeAlternative = generateSafeAlternative(userMessage);

      //   // –î–ª—è retry –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –∑–∞–º–µ–Ω—É
      //   if (retryCount > 0) {
      //     // –ë–æ–ª–µ–µ —Ä–∞–¥–∏–∫–∞–ª—å–Ω–∞—è –∑–∞–º–µ–Ω–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
      //     userMessage = safeAlternative.replace(/—Ä–∞–±–æ—Ç[–∞-—è]*/gi, '—É—á–∏–º—Å—è')
      //       .replace(/–¥–∞–≤–∞–π/gi, '—Å–∫–∞–∂–∏')
      //       .replace(/–ø—Ä–æ–¥–æ–ª–∂[–∞-—è]*/gi, '–¥–∞–≤–∞–π')
      //       .replace(/–Ω–∞—á–Ω[–∞-—è]*/gi, '—Å–∫–∞–∂–∏');
      //     console.log('üîÑ –†–∞–¥–∏–∫–∞–ª—å–Ω–∞—è –∑–∞–º–µ–Ω–∞ –¥–ª—è retry:', userMessage);
      //   } else if (safeAlternative !== userMessage) {
      //     console.log('üîÑ –ó–∞–º–µ–Ω–∞ –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É:', safeAlternative);
      //     userMessage = safeAlternative;
      //   }
      // }

      // –î–ª—è retry –ø–æ–ø—ã—Ç–æ–∫ –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
      if (retryCount > 0) {
        const prefixes = [
          '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—ä—è—Å–Ω–∏:',
          '–†–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ –ø—Ä–æ:',
          '–ü–æ–º–æ–≥–∏ –º–Ω–µ —Å:',
          '–Ø —Ö–æ—á—É —É–∑–Ω–∞—Ç—å:',
          '–û–±—ä—è—Å–Ω–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞:'
        ];
        const prefix = prefixes[retryCount - 1] || '–°–∫–∞–∂–∏ –º–Ω–µ:';
        userMessage = `${prefix} ${userMessage}`;
        console.log('üìù –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è retry:', userMessage);
      }

      // Get user profile if not loaded
      let profile = userProfile;
      if (!profile) {
        profile = await getUserProfile();
      }

      // Get course information
      const courseName = getCourseDisplayName(courseId || "");

      // Build context information
      const contextInfo = [];
      if (courseName) {
        contextInfo.push(`–ö—É—Ä—Å: ${courseName}`);
      }
      if (profile) {
        console.log('üìä –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è LLM:', profile);
        if (profile.learning_style) {
          contextInfo.push(`–°—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è: ${profile.learning_style}`);
        }
        if (profile.difficulty_level) {
          contextInfo.push(`–£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: ${profile.difficulty_level}`);
        }
        if (profile.interests && profile.interests.length > 0) {
          contextInfo.push(`–ò–Ω—Ç–µ—Ä–µ—Å—ã: ${profile.interests.join(', ')}`);
        }
      }

      const contextString = contextInfo.length > 0 ? `\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: ${contextInfo.join('; ')}` : '';
      const startTime = Date.now();

      if (!token) {
        console.error('‚ùå –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω, –æ—Ç–º–µ–Ω–∞ –∑–∞–ø—Ä–æ—Å–∞');
        toast({
          title: "–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏",
          description: "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–æ–π–¥–∏—Ç–µ –≤ —Å–∏—Å—Ç–µ–º—É –∑–∞–Ω–æ–≤–æ",
          variant: "destructive"
        });
        return "–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏";
      }

      console.log('üîë Token check:', { length: token.length, start: token.substring(0, 10) + '...' });

      // Determine endpoint and body based on courseId
      let endpoint = 'https://teacher.windexs.ru/api/chat/general';
      let body: any = {
        content: userMessage + contextString, // Server expects 'content'
        messageType: 'text'
      };

      if (courseId && courseId !== 'general') {
        endpoint = `https://teacher.windexs.ru/api/chat/${courseId}/message`;
      }

      let response;
      try {
        response = await fetch(endpoint, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${token}`
          },
          body: JSON.stringify(body)
        });
      } catch (fetchError) {
        console.error('‚ùå Fetch error:', fetchError);
        throw fetchError;
      }

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–æ –ª–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –≤–æ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞
      if (generationIdRef.current !== startGenId) {
        console.log('üõë –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±—ã–ª–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –≤–æ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM');
        return '';
      }

      if (!response.ok) {
        console.error('‚ùå Server returned error:', response.status, response.statusText);
        if (response.status === 401) {
          toast({
            title: "–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏",
            description: "–°–µ—Å—Å–∏—è –∏—Å—Ç–µ–∫–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É.",
            variant: "destructive"
          });
        }
        throw new Error(`Failed to get response from LLM: ${response.status}`);
      }

      const textData = await response.text();
      // console.log('üì• Raw server response:', textData.substring(0, 500)); 

      let data;
      try {
        // –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π JSON
        data = JSON.parse(textData);
      } catch (parseError) {
        // –ï—Å–ª–∏ –Ω–µ –≤—ã—à–ª–æ, –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ SSE –ª–∏ —ç—Ç–æ (Server-Sent Events)
        if (textData.trim().startsWith('data:')) {
          console.log('üåä –û–±–Ω–∞—Ä—É–∂–µ–Ω SSE –ø–æ—Ç–æ–∫, —Å–æ–±–∏—Ä–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ...');
          const lines = textData.split('\n');
          let fullMessage = '';
          let messageId = '';

          for (const line of lines) {
            const trimmedLine = line.trim();
            if (trimmedLine.startsWith('data: ')) {
              const jsonStr = trimmedLine.substring(6);
              try {
                const chunk = JSON.parse(jsonStr);
                if (chunk.content) {
                  fullMessage += chunk.content;
                }
                if (chunk.messageId) {
                  messageId = chunk.messageId;
                }
              } catch (e) {
                // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –±–∏—Ç—ã–µ —á–∞–Ω–∫–∏
              }
            }
          }

          data = { message: fullMessage, messageId };
        } else {
          console.error('‚ùå JSON Parse Error:', parseError);
          console.error('‚ùå Failed content:', textData.substring(0, 200) + '...');
          throw new Error('Invalid JSON response from server');
        }
      }

      console.log('ü§ñ –û—Ç–≤–µ—Ç –æ—Ç LLM –ø–æ–ª—É—á–µ–Ω (–¥–ª–∏–Ω–∞):', data.message?.length);

      // –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
      // monitorLLMResponse(
      //   userMessage,
      //   courseId || 'unknown',
      //   data.message,
      //   'msg_' + Date.now(),
      //   Date.now() - startTime
      // );

      // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –∏ retry –ª–æ–≥–∏–∫–∞
      if (!data.message || data.message.trim().length === 0) {
        console.warn('‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM');

        if (retryCount < MAX_RETRIES) {
          console.log(`üîÑ –ó–∞–ø—É—Å–∫ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏ ${retryCount + 1}...`);
          // –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
          const delay = Math.pow(2, retryCount) * 500;
          await new Promise(resolve => setTimeout(resolve, delay));
          return sendToLLM(originalMessage, retryCount + 1);
        } else {
          console.error('‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –∏—Å—á–µ—Ä–ø–∞–Ω—ã');
          // –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—É—é —Ñ—Ä–∞–∑—É
          return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —Ä–∞—Å—Å–ª—ã—à–∞–ª–∞. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.";
        }
      }

      // –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —É—Å–ø–µ—à–Ω–æ–º –æ—Ç–≤–µ—Ç–µ (–µ—Å–ª–∏ —ç—Ç–æ –±—ã–ª retry)
      if (retryCount > 0) {
        console.log('üéì –û–±—É—á–µ–Ω–∏–µ: –∑–∞–ø–æ–º–∏–Ω–∞–µ–º —É—Å–ø–µ—à–Ω—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É –¥–ª—è:', originalMessage);
        // updateLearnedAlternatives(originalMessage, userMessage); // Disabled due to type mismatch
      }

      return data.message;
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –æ–±—â–µ–Ω–∏—è —Å LLM:', error);

      // Retry –ø—Ä–∏ –æ—à–∏–±–∫–µ —Å–µ—Ç–∏
      if (retryCount < MAX_RETRIES) {
        console.log(`üîÑ –û—à–∏–±–∫–∞ —Å–µ—Ç–∏, –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ ${retryCount + 1}...`);
        await new Promise(resolve => setTimeout(resolve, 1000));
        return sendToLLM(originalMessage, retryCount + 1);
      }

      toast({
        title: "–û—à–∏–±–∫–∞",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞",
        variant: "destructive"
      });
      return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ —Å–≤—è–∑–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.";
    } finally {
      // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –±—ã–ª –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–∫—Ç–∏–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å
      if (generationIdRef.current === startGenId) {
        setIsGeneratingResponse(false);
      }
    }
  }, [token, courseId, userProfile, toast]);

  // Speak text using OpenAI TTS
  const speakText = useCallback(async (text: string) => {
    if (!text || !isSoundEnabled) return;

    // –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º generationId
    const startGenId = generationIdRef.current;

    try {
      console.log('üîä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–∑–≤—É—á–∫–∏ –¥–ª—è:', text);
      setIsSpeaking(true);
      isPlayingAudioRef.current = true;
      currentTTSTextRef.current = text; // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —ç—Ö–∞

      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
      ttsProgressRef.current = {
        startTime: Date.now(),
        text: text,
        duration: text.length * 60, // –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: 60–º—Å –Ω–∞ —Å–∏–º–≤–æ–ª
        words: text.split(' '),
        currentWordIndex: 0
      };

      const response = await fetch('https://teacher.windexs.ru/api/tts', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${token}`
        },
        body: JSON.stringify({
          text,
          voice: 'nova', // –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ–ª–æ—Å nova (–∫–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏)
          model: 'tts-1-hd' // HD –º–æ–¥–µ–ª—å –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        })
      });

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ
      if (generationIdRef.current !== startGenId) {
        console.log('üõë –û–∑–≤—É—á–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –¥–æ –Ω–∞—á–∞–ª–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è');
        return;
      }

      if (!response.ok) {
        throw new Error('Failed to generate speech');
      }

      const audioBlob = await response.blob();
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      currentAudioRef.current = audio;

      // Event handlers
      audio.onplay = () => {
        console.log('üîä –û–∑–≤—É—á–∫–∞ –Ω–∞—á–∞—Ç–∞');
      };

      audio.onended = () => {
        console.log('‚úÖ –û–∑–≤—É—á–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞');
        URL.revokeObjectURL(audioUrl);
        currentAudioRef.current = null;
        isPlayingAudioRef.current = false;
        setIsSpeaking(false);
        // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
        ttsProgressRef.current = null;
      };

      audio.onerror = (event) => {
        console.error('‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ:', event);
        URL.revokeObjectURL(audioUrl);
        currentAudioRef.current = null;
        isPlayingAudioRef.current = false; // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        setIsSpeaking(false);
        // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–∑–≤—É—á–∫–∏
        ttsProgressRef.current = null;

        // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        if (speechRecognitionRef.current && isRecording) {
          try {
            speechRecognitionRef.current.stop();
            setIsRecording(false);
          } catch (e) {
            console.log('‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ TTS:', e);
          }
        }
        toast({
          title: "–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏",
          description: "–ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –∞—É–¥–∏–æ",
          variant: "destructive"
        });
      };

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ–º
      if (generationIdRef.current !== startGenId) {
        console.log('üõë –û–∑–≤—É—á–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–µ—Ä–µ–¥ play()');
        return;
      }

      await audio.play();

    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ TTS:', error);
      setIsSpeaking(false);
      isPlayingAudioRef.current = false;
      ttsProgressRef.current = null;
    }
  }, [token, isSoundEnabled, toast, isRecording]);

  // Load user profile on mount
  useEffect(() => {
    getUserProfile();
  }, [getUserProfile]);

  // Clean up on unmount
  useEffect(() => {
    return () => {
      if (speechRecognitionRef.current) {
        try {
          speechRecognitionRef.current.stop();
        } catch (e) { }
      }
      if (currentAudioRef.current) {
        currentAudioRef.current.pause();
        currentAudioRef.current = null;
      }
      if (mediaRecorderRef.current) {
        try {
          mediaRecorderRef.current.stop();
        } catch (e) { }
      }
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  // Determine Orb state
  const orbState = useMemo(() => {
    if (isSpeaking) return 'speaking';
    if (isGeneratingResponse) return 'processing';
    if (isRecording && isTranscribing) return 'listening';
    if (isRecording) return 'listening';
    return 'idle';
  }, [isSpeaking, isGeneratingResponse, isRecording, isTranscribing]);

  // Determine status text
  const statusText = useMemo(() => {
    if (isSpeaking) return '–ì–æ–≤–æ—Ä—é...';
    if (isGeneratingResponse) return '–î—É–º–∞—é...';
    if (isRecording) return '–°–ª—É—à–∞—é...';
    return '–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å';
  }, [isSpeaking, isGeneratingResponse, isRecording]);

  return (
    <div className="relative w-full h-screen bg-black overflow-hidden flex flex-col items-center justify-center font-sans">
      {/* Background Stars */}
      <BackgroundStars />

      {/* Navigation / Back Button */}
      <div className="absolute top-6 left-6 z-50">
        <Button
          variant="ghost"
          size="icon"
          className="text-white/70 hover:text-white hover:bg-white/10 rounded-full w-12 h-12"
          onClick={() => navigate(-1)}
        >
          <ArrowLeft className="w-6 h-6" />
        </Button>
      </div>

      {/* Main Content */}
      <div className="z-10 flex flex-col items-center justify-center space-y-12 w-full max-w-4xl px-4">

        {/* Assistant Orb */}
        <div className="relative flex items-center justify-center">
          <AssistantOrb state={orbState} />
        </div>

        {/* Status & Transcript */}
        <div className="flex flex-col items-center space-y-6 text-center max-w-2xl">
          <div className="text-white/90 text-2xl font-light tracking-widest uppercase animate-pulse">
            {statusText}
          </div>

          {transcriptDisplay && (
            <div className="text-white/70 text-lg font-light leading-relaxed backdrop-blur-sm bg-black/30 p-4 rounded-xl border border-white/10 transition-all duration-300">
              "{transcriptDisplay}"
            </div>
          )}
        </div>
      </div>

      {/* Controls */}
      <div className="absolute bottom-12 z-50 flex items-center space-x-8">
        {/* Sound Toggle */}
        <Button
          variant="ghost"
          size="icon"
          className={`w-14 h-14 rounded-full transition-all duration-300 ${isSoundEnabled ? 'bg-white/10 text-white hover:bg-white/20' : 'bg-red-500/20 text-red-400 hover:bg-red-500/30'}`}
          onClick={handleToggleSound}
        >
          {isSoundEnabled ? <Volume2 className="w-6 h-6" /> : <VolumeX className="w-6 h-6" />}
        </Button>

        {/* Mic Toggle (Main Action) */}
        <Button
          variant="default"
          size="icon"
          className={`w-20 h-20 rounded-full shadow-[0_0_40px_-10px_rgba(255,255,255,0.3)] transition-all duration-500 transform hover:scale-105 ${isRecording
            ? 'bg-red-500 hover:bg-red-600 shadow-[0_0_50px_-10px_rgba(239,68,68,0.5)]'
            : 'bg-white text-black hover:bg-gray-200'
            }`}
          onClick={handleStartStopRecording}
        >
          {isRecording ? (
            <MicOff className="w-8 h-8" />
          ) : (
            <Mic className="w-8 h-8" />
          )}
        </Button>

        {/* End Call (Exit) */}
        <Button
          variant="ghost"
          size="icon"
          className="w-14 h-14 rounded-full bg-red-500/20 text-red-400 hover:bg-red-500/30 hover:text-red-300 transition-all duration-300"
          onClick={() => navigate(-1)}
        >
          <PhoneOff className="w-6 h-6" />
        </Button>
      </div>
    </div>
  );
};

export default VoiceChat;
